{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab4de378",
   "metadata": {},
   "source": [
    "# True or False Exercises\n",
    "\n",
    "## Question 1\n",
    "**Question:**  \n",
    "Clusters are always computed using the Euclidean distance metric.\n",
    "\n",
    "**Answer:**  \n",
    "\n",
    "---\n",
    "\n",
    "## Question 2\n",
    "**Question:**  \n",
    "The K-means algorithm is a randomized algorithm that may yield a different set of clusters every time it is run.\n",
    "\n",
    "**Answer:**  \n",
    "\n",
    "---\n",
    "\n",
    "## Question 3\n",
    "**Question:**  \n",
    "The K-means algorithm always converges to the minimizer of the K-means objective function.\n",
    "\n",
    "**Answer:**  \n",
    "\n",
    "---\n",
    "\n",
    "## Question 4\n",
    "**Question:**  \n",
    "The K-means clusters are always better than the hierarchical clusters in terms of average silhouette score.\n",
    "\n",
    "**Answer:**  \n",
    "\n",
    "---\n",
    "\n",
    "## Question 5\n",
    "**Question:**  \n",
    "One way to define a \"good\" cluster is by quantifying the tightness and distinctness of the cluster.\n",
    "\n",
    "**Answer:**  \n",
    "\n",
    "---\n",
    "\n",
    "## Question 6\n",
    "**Question:**  \n",
    "It is possible to compute the cluster centers of clusters generated from the hierarchical clustering algorithm (even though the hierarchical clustering algorithm does not itself involve computing cluster centers).\n",
    "\n",
    "**Answer:**  \n",
    "\n",
    "---\n",
    "\n",
    "## Question 7\n",
    "**Question:**  \n",
    "The Rand Index can be used to compare two sets of clusters only when each set contains the same number of clusters.\n",
    "\n",
    "**Answer:**  \n",
    "\n",
    "---\n",
    "\n",
    "## Question 8\n",
    "**Question:**  \n",
    "The Rand Index can be used to compare two sets of clusters only for the same set of data points.\n",
    "\n",
    "**Answer:**  \n",
    "\n",
    "---\n",
    "\n",
    "## Question 9\n",
    "**Question:**  \n",
    "The WSS can be used to compare two sets of clusters that each consist of different numbers of clusters.\n",
    "\n",
    "**Answer:**  \n",
    "\n",
    "---\n",
    "\n",
    "## Question 10\n",
    "**Question:**  \n",
    "The silhouette score can be used to compare two sets of clusters that each consist of different numbers of clusters.\n",
    "\n",
    "**Answer:**  \n",
    "\n",
    "---\n",
    "\n",
    "## Question 11\n",
    "**Question:**  \n",
    "Cross-validation is used widely in data science for conducting hyperparameter selection (i.e., it is not solely used for clustering problems).\n",
    "\n",
    "**Answer:**  \n",
    "\n",
    "---\n",
    "\n",
    "## Question 12\n",
    "**Question:**  \n",
    "Cross-validation provides a reasonable approximation to the performance of an algorithm on external data.\n",
    "\n",
    "**Answer:**  \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445d817b",
   "metadata": {},
   "source": [
    "\n",
    "# Conceptual Exercises\n",
    "\n",
    "## Question 1\n",
    "**Question:**  \n",
    "Since there are generally no \"ground truth\" clusters, how can you obtain evidence that a set of clusters are trustworthy? Provide at least two techniques that you might use to demonstrate the trustworthiness of a set of clusters.\n",
    "\n",
    "**Answer:**  \n",
    "\n",
    "---\n",
    "\n",
    "## Question 2\n",
    "**Question:**  \n",
    "Describe at least one technique that you could use to choose (the number of clusters).\n",
    "\n",
    "**Answer:**  \n",
    "\n",
    "---\n",
    "\n",
    "## Question 3\n",
    "**Question:**  \n",
    "Suppose that you have a set of clusters that have been computed for a dataset that has more than two variables/dimensions. Explain how a two-dimensional scatterplot can be used to visualize the clusters.\n",
    "\n",
    "**Answer:**  \n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Question 4\n",
    "**Question:**  \n",
    "List two other techniques that you can use to explore the clusters.\n",
    "\n",
    "**Answer:**  \n",
    "\n",
    "---\n",
    "\n",
    "## Question 5\n",
    "**Question:**  \n",
    "The Rand Index is one example of a measure that quantifies the similarity between two sets of clusters. Create another measure that could be used to quantify the similarity between two sets of clusters (your measure can be much \"simpler\" than the Rand Index, and could just focus on the cluster centers, for example).\n",
    "\n",
    "**Answer:**  \n",
    "\n",
    "---\n",
    "\n",
    "## Question 6\n",
    "**Question:**  \n",
    "Identify at least three sources of uncertainty (arising at any point in the DSLC) that are associated with the cluster results obtained from the K-means clustering algorithm applied to the nutrition data. That is, identify three factors that might lead to alternative clustering results.\n",
    "\n",
    "**Answer:**  \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56df5f2",
   "metadata": {},
   "source": [
    "\n",
    "# Mathematical Exercises\n",
    "\n",
    "## Question 1\n",
    "**Question:**  \n",
    "Rewrite the formula for computing WSS in Equation 7.5 instead using:\n",
    "1. The Euclidean distance metric (rather than squared Euclidean distance).\n",
    "2. The Manhattan distance metric.\n",
    "\n",
    "**Answer:**  \n",
    "\n",
    "---\n",
    "\n",
    "## Question 2\n",
    "**Question:**  \n",
    "Show that the K-means objective function (based on the squared Euclidean distance) from equation (Equation 7.4) does not change when you mean-center the data.\n",
    "\n",
    "**Answer:**  \n",
    "\n",
    "---\n",
    "\n",
    "## Question 3\n",
    "**Question:**  \n",
    "The following table shows the original (unscaled) iron, sodium, and protein measurements for three food items. Compute the Euclidean distance and the Manhattan distance between each pair of food items using all three variables.\n",
    "\n",
    "**Answer:**  \n",
    "\n",
    "---\n",
    "\n",
    "## Question 4\n",
    "**Question:**  \n",
    "If the standard deviation of the iron, sodium, and protein nutrient variables are given, recompute the Euclidean distance and the Manhattan distance using the SD-scaled variables. Do the relative distances change? If so, explain why.\n",
    "\n",
    "**Answer:**  \n",
    "\n",
    "---\n",
    "\n",
    "## Question 5\n",
    "**Question:**  \n",
    "If these three food items all belong to the same cluster whose center is given (based on the SD-scaled variables), compute the portion of the WSS that is attributed to these three food items.\n",
    "\n",
    "**Answer:**  \n",
    "\n",
    "---\n",
    "\n",
    "## Question 6\n",
    "**Question:**  \n",
    "Show that the TSS can be decomposed into the sum of the WSS and the BSS.\n",
    "\n",
    "**Answer:**  \n",
    "\n",
    "---\n",
    "\n",
    "## Question 7\n",
    "**Question:**  \n",
    "Compute the TSS, BSS, and WSS for both versions 1 and 2 of the clusters for the eight-data point example in Section 7.5.1. Confirm that TSS = WSS + BSS.\n",
    "\n",
    "**Answer:**  \n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9411012a",
   "metadata": {},
   "source": [
    "# Coding Exercises\n",
    "\n",
    "## Question 1\n",
    "**Question:**  \n",
    "At the end of the 04_clustering.qmd (or .ipynb) file in the relevant nutrition/dslc_documentation/ subfolder of the supplementary GitHub repository, you will find a section labeled “[Exercise: to complete]”. In this section, write some code that applies the K-means and hierarchical clustering algorithms to cluster the nutrients/columns (rather than the food items/rows) using correlation as the similarity measure. Compare your results to the nutrient groups that we used in Chapter 6 (you can base your choice of K on these original nutrient groups). Hint: in R, both the kmeans() and hclust() R functions accept a custom distance matrix and you can convert a correlation matrix to a distance matrix (in which smaller numbers should mean “more similar”) using 1-|cor|.\n",
    "\n",
    "**Answer:**  \n",
    "\n",
    "---\n",
    "\n",
    "## Question 2\n",
    "**Question:**\n",
    "Apply the hierarchical clustering and K-means algorithms (with K = 30) to cluster the food items using the principal component-transformed dataset that we computed in Chapter 6. Compare the results with the clusters computed on the original data.\n",
    "\n",
    "**Answer:**  \n",
    "\n",
    "---\n",
    "\n",
    "## Question 3\n",
    "**Question:**\n",
    "The goal of this exercise is to conduct a simulation study to understand how quickly the Rand Index and the adjusted Rand Index deteriorate as we increasingly perturb a set of clusters. You can complete this exercise at the end of the 04_clustering.qmd (or .ipynb) file in the nutrition/dslc_documentation/ subfolder of the supplementary GitHub repository if you wish.\n",
    "\n",
    "    1. Use the kmeans() function in R or the cluster.KMeans() class from the scikit-learn library in Python to cluster the (SD-scaled and log-transformed) food items into groups.\n",
    "\n",
    "    2. Randomly perturb 5 percent of the cluster membership entries. That is, choose 5 percent of the entries of the cluster membership vector and randomly perturb them (e.g., using the sample() function in R). For instance, if the selected entries of the membership vector were {3, 1, 3, 3, 2, 2, 4} (i.e., the first observation is in cluster 3, the second observation is in cluster 1, etc.), then one possible perturbation is {3, 3, 4, 3, 2, 1, 2}.\n",
    "\n",
    "    3. Compute the Rand Index and the adjusted Rand Index for the new cluster membership vector and the original unperturbed cluster membership vector. R users may want to use the rand.index() and adj.rand.index() functions from the fossil R package, and Python users may want to use the metrics.rand_score() and metrics.adjusted_rand_score() functions from the scikit-learn library. Comment on the results.\n",
    "\n",
    "    4. Repeat the previous steps of this exercise, this time perturbing 10, 20, and 50 percent of the data point’s cluster memberships. Comment on what you find.\n",
    "\n",
    "    5. Create a line plot with two lines (or two line plots, each with one line), showing (a) how the Rand Index (-axis) changes as the proportion of data points whose cluster membership is being perturbed (-axis) increases, and (b) how the adjusted Rand Index (-axis) changes as the proportion of data points whose cluster membership is being perturbed (-axis) increases.\n",
    "\n",
    "**Answer:**  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487b700f",
   "metadata": {},
   "source": [
    "# Project Exercises\n",
    "\n",
    "## Question 1\n",
    "**Question:**  \n",
    "**Clustering houses in Ames, Iowa** The ames_houses/data/ folder in the supplementary GitHub repository contains data on the sale price and properties of each house sold in Ames, Iowa, between 2006 to 2010. This data was provided by the Ames assessor’s office and was obtained and presented by De Cock (2011). We will be using this data throughout several of the chapters in part III of this book, where our goal will be to develop a predictive algorithm for predicting the sale price of houses in Ames. For this exercise, your goal is to identify some clusters of the houses in this dataset.\n",
    "\n",
    "    1. The 01_cleaning.qmd and 02_eda.qmd (or .ipynb) files, which can be found in the ames_houses/dslc_documentation/ subfolder contain one example of the cleaning and exploratory data analysis (EDA) workflow for the data. Read through these files and run the code that they contain.\n",
    "\n",
    "    2. By editing the 03_clustering.qmd (or .ipynb) file in the relevant ames_houses/dslc_documentation/ subfolder, conduct a cluster analysis on the housing data. Your analysis should include choosing the value of  (e.g., using CV), as well as conducting a PCS analysis of the results (assess the clusters on the withheld validation set and conduct some stability analyses to assess at least two sources of uncertainty).\n",
    "\n",
    "    3. Summarize your clusters. What types of houses does each cluster contain?\n",
    "**Answer:**  \n",
    "\n",
    "---\n",
    "\n",
    "## Question 2\n",
    "**Question:**  \n",
    "**Clustering activities using smartphone sensor data** The folder in the supplementary GitHub repository called exercises/smartphone/data/ contains hundreds of measurements taken from the accelerometer and gyroscope of the smartphones of 30 volunteers (who have been split into a training and validation set) while they were conducting any of six activities (walking, walking upstairs, walking downstairs, sitting, standing, lying down). This data was collected by Anguita et al. (2013) and is hosted on the UCI Machine Learning repository.\n",
    "\n",
    "    1. The 01_cleaning.qmd (or .ipynb) code/documentation file in the relevant exercises/smartphone/dslc_documentation/ subfolder contains a template for conducting the data cleaning process for this smartphone data (we have provided some initial code for loading in the data). Clean this smartphone activity data yourself by filling in this cleaning file and write a function for cleaning and preprocessing the data (and save it in a file called prepareActivityData.R or .py in the exercises/smartphone/dslc_documentation/functions/ folder).\n",
    "\n",
    "    2. Comment on how the data has been split into training and validation sets. Which splitting technique (time-based, group-based, or random) was used? Based on how the clustering results may be used in the future, do you think that the splitting technique is reasonable?\n",
    "\n",
    "    3. In the 02_eda.qmd (or .ipynb) code/documentation file in the relevant exercises/smartphone/dslc_documentation/ subfolder, conduct an EDA of your cleaned smartphone activity dataset. Be sure to create at least one explanatory figure and conduct a PCS analysis of your results.\n",
    "\n",
    "    4. In the 03_clustering.qmd (or .ipynb) code/documentation file in the relevant exercises/smartphone/dslc_documentation/ subfolder, conduct a cluster analysis of this dataset. Specifically, you should try to identify  clusters of activities without using the activity labels.\n",
    "\n",
    "    5. Visualize your clusters. Comment on what you see. For example, do they seem to be fairly distinct?\n",
    "\n",
    "    6. Conduct a principal component analysis of the activity data and visualize your original clusters in the space defined by the first two principal components using a scatterplot. You may also wish to try recomputing your clusters using your principal component-transformed dataset.\n",
    "\n",
    "    7. Conduct a PCS analysis of your most interesting results. Specifically, assess the predictability of your clusters by assessing the clusters on the withheld validation set and conduct some stability analyses to assess at least two sources of uncertainty.\n",
    "\n",
    "    8. For the training data, compare the clusters that you identified with the “true” activity labels (numeric labels are contained in the data/train/y_train.txt file, and the data/activity_labels.txt file connects these numeric labels to the actual activities). Do your clusters seem to correspond to the activities?\n",
    "**Answer:**  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa32e80",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
