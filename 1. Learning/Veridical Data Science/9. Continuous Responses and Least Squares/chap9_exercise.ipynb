{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae868fc3",
   "metadata": {},
   "source": [
    "# True or False Exercises\n",
    "\n",
    "## Question 1\n",
    "**Question:**  \n",
    "For any given set of training data points, there is an explicit mathematical formula that we can use to compute the parameters of the LAD line (i.e., the line that will minimize the absolute value loss function).\n",
    "\n",
    "**Answer:**  \n",
    "\n",
    "---\n",
    "\n",
    "## Question 2\n",
    "**Question:**  \n",
    "For any given set of training data points, there is an explicit mathematical formula that we can use to compute the parameters of the LS line (i.e., the line that will minimize the squared loss function).\n",
    "\n",
    "**Answer:**  \n",
    "\n",
    "---\n",
    "\n",
    "## Question 3\n",
    "**Question:**  \n",
    "The loss function that you used to train your predictive algorithm must match the loss function that you use to evaluate the predictions.\n",
    "\n",
    "**Answer:**  \n",
    "\n",
    "---\n",
    "\n",
    "## Question 4\n",
    "**Question:**  \n",
    "The LAD algorithm will always produce more accurate predictions on the validation set than the LS algorithm when using the MAE predictive performance measure.\n",
    "\n",
    "**Answer:**  \n",
    "\n",
    "---\n",
    "\n",
    "## Question 5\n",
    "**Question:**  \n",
    "The rMSE is on the same scale as the MAE.\n",
    "\n",
    "**Answer:**  \n",
    "\n",
    "---\n",
    "\n",
    "## Question 6\n",
    "**Question:**  \n",
    "If you have trained two predictive algorithms, it is possible for one to perform better according to the validation dataset MSE and the other to perform better according to the validation dataset MAE.\n",
    "\n",
    "**Answer:**  \n",
    "\n",
    "---\n",
    "\n",
    "## Question 7\n",
    "**Question:**  \n",
    "It is acceptable to use a predictive algorithm to predict the response of future data points that are quite different from the training data if you have shown that the algorithm generates accurate predictions for data points similar to the future data points.\n",
    "\n",
    "**Answer:**  \n",
    "\n",
    "---\n",
    "\n",
    "## Question 8\n",
    "**Question:**  \n",
    "The prediction error computed on the training data does not provide an appropriate assessment of how the algorithm will perform on future data.\n",
    "\n",
    "**Answer:**  \n",
    "\n",
    "---\n",
    "\n",
    "## Question 9\n",
    "**Question:**  \n",
    "One example of a PCS predictability assessment of a predictive algorithm is to compute the MAE for the predictions computed for the training data.\n",
    "\n",
    "**Answer:**  \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb639773",
   "metadata": {},
   "source": [
    "# Conceptual Exercises\n",
    "\n",
    "## Question 1\n",
    "**Question:**  \n",
    "Explain what we mean when we say that \"the LAD algorithm is more robust to outliers than the LS algorithm\", and explain why this is the case.\n",
    "\n",
    "**Answer:**  \n",
    "\n",
    "---\n",
    "\n",
    "## Question 2\n",
    "**Question:**  \n",
    "Provide two reasons why the LS algorithm is more common in practice than the LAD algorithm.\n",
    "\n",
    "**Answer:**  \n",
    "\n",
    "---\n",
    "\n",
    "## Question 3\n",
    "**Question:**  \n",
    "One possible fitted line for predicting sale price using area is given by ŷ = 12,000 + 121 x area.  \n",
    "1. What does the intercept term being equal to 12,000 tell you?  \n",
    "2. What does the area coefficient term being equal to 121 tell you?  \n",
    "3. Suppose you have also computed another line given by `predicted price = 10,000 + 122 x area`. How would you use the validation dataset to compare two fitted lines?  \n",
    "4. Compute the predicted price of a 2,000-square-foot house.\n",
    "\n",
    "**Answer:**  \n",
    "\n",
    "---\n",
    "\n",
    "## Question 4\n",
    "**Question:**  \n",
    "Explain why the training dataset MSE will always be lower for an LS fitted line than for an LAD fitted line (when both lines are computed using the same training dataset). Is this also the case when MSE is computed based on the validation dataset predictions?\n",
    "\n",
    "**Answer:**  \n",
    "\n",
    "---\n",
    "\n",
    "## Question 5\n",
    "**Question:**  \n",
    "Provide one pro and one con of using the correlation performance measure (vs the rMSE performance measure).\n",
    "\n",
    "**Answer:**  \n",
    "\n",
    "---\n",
    "\n",
    "# Mathematical Exercises\n",
    "\n",
    "## Question 1\n",
    "**Question:**  \n",
    "For a fitted line of the form ŷ = b₀ + b₁ x area:  \n",
    "1. Show that the predicted price of a 0-square-foot house is equal to b₀  \n",
    "2. Show that the predicted price increases by b₁ when living area increases by 1\n",
    "\n",
    "**Answer:**  \n",
    "\n",
    "---\n",
    "\n",
    "## Question 2\n",
    "**Question:**  \n",
    "The LS algorithm for generating fits of the form y = b0 + b1 x  aims to find the values of b0 and b1 that minimize the squared loss function, which is given by loss function 1/n sum of i = 1 to n (yi - (b0 + b1xi))^2.\n",
    "1. By differentiating the squared loss function in terms of b0 and setting the derivative to zero, show that the value of b0 that minimizes the squared loss is given by b0 = mean of y - b1 * mean of x. \n",
    "2. By differentiating the squared loss function in terms of b1 and setting the derivative to zero (you can substitute in the value of b0 that you computed previously), show that the value of b1 that minimizes the squared loss is given by sum of i for 1 to n (xi - mean of x)(yi - mean of y) / sum of i for n (xi - mean of x)^2\n",
    "\n",
    "**Answer:**  \n",
    "\n",
    "---\n",
    "\n",
    "## Question 3\n",
    "**Question:**  \n",
    "Adapt your computations for exercise 2 to find the LS coefficients b0 and b1 for the following simpler fits:\n",
    "1. y = b0\n",
    "2. y = b1x \n",
    "\n",
    "**Answer:**  \n",
    "\n",
    "---\n",
    "\n",
    "## Question 4\n",
    "**Question:**  \n",
    "Suppose that you are trying to develop an LS linear fit for predicting student scores on a final end-of-semester exam based on their score on a midterm exam (both are out of 100). To compute your LS fit, you plan to use the scores from the 15 students who took the class last year. The following table shows the previous year’s student’s scores in the midterm and final exams:1. Write the linear model format  \n",
    "| Student | Midterm | Final |\n",
    "|---------|---------|-------|\n",
    "| 1       | 24      | 50    |\n",
    "| 2       | 48      | 52    |\n",
    "| 3       | 48      | 52    |\n",
    "| 4       | 52      | 52    |\n",
    "| 5       | 47      | 59    |\n",
    "| 6       | 46      | 69    |\n",
    "| 7       | 56      | 76    |\n",
    "| 8       | 81      | 78    |\n",
    "| 9       | 62      | 82    |\n",
    "| 10      | 80      | 88    |\n",
    "| 11      | 65      | 88    |\n",
    "| 12      | 82      | 90    |\n",
    "| 13      | 71      | 94    |\n",
    "| 14      | 95      | 96    |\n",
    "| 15      | 98      | 98    |\n",
    "1. Write the format of the line you are trying to compute in terms of the “midterm” and “final” variables and the b0 and b1 parameters (you don’t need to compute the values of b0 and b1 yet).\n",
    "2. Compute the LS fitted line coefficients b0 and b1 by hand (using the formulas provided in this chapter) and write the equation of your fitted line (i.e., plug in the values of b0 and b1 for the line you identified for the previous task).  \n",
    "3. Interpret the coefficients  \n",
    "4. Predict final score for midterm=75  \n",
    "5. Predict final score for midterm=99\n",
    "\n",
    "**Answer:**  \n",
    "\n",
    "---\n",
    "\n",
    "## Question 5\n",
    "**Question:**  \n",
    "Show that Corr(x,y) * SD(y) / SD(x) = sum of i for 1 to n (xi - mean of x)(yi - mean of y) / sum of i for n (xi - mean of x)^2\n",
    "\n",
    "**Answer:**  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c23ed4",
   "metadata": {},
   "source": [
    "# Coding Exercises\n",
    "\n",
    "## Question 1\n",
    "**Question:**  \n",
    "Using exam scores data (exercises/exam_scores/data/scores.csv):  \n",
    "1. Create scatterplot of midterm vs final scores for the 15 students\n",
    "2. Compute correlation. Based on the scatterplot and correlation computation, do you think that the midterm exam score is likely to be a good predictor of the final exam score?\n",
    "3. Fit LAD, in Python, you can use the linear_model.LADRegression() class from the sklego library.\n",
    "4. Fit LS model (linear_model.LinearRegression() class from the scikit-learn library in Python) to generate another linear fit for the final exam scores based on the midterm scores.\n",
    "5. Using each fit, predict the final exam score of a student who got 75 on the midterm exam.\n",
    "6. Add your LAD and LS fitted lines to the scatterplot you produced in part (a) (if you’re using ggplot you may find the function geom_abline() useful).\n",
    "7. The file scores_val.csv contains the midterm and final exam scores for 12 students who took the class during the summer session. Compute a predictability analysis of each of your fits trained on the 15 original scores by evaluating the predictive performance for these summer session students. Compute the rMSE, MAE, MAD, and correlation values in your evaluation, and visualize the relationship between the observed and predicted responses using a scatterplot.\n",
    "8. Conduct a stability analysis in which you examine the uncertainty associated with the data collection (i.e., by conducting reasonable data perturbations). Justify the perturbations that you choose, and create a prediction stability plot for each algorithm (the ggplot function geom_segment() will be helpful for creating the line segments in R). Comment on your findings.\n",
    "\n",
    "**Answer:**  \n",
    "\n",
    "---\n",
    "\n",
    "## Question 2\n",
    "**Question:**  \n",
    "Repeat the Ames house price prediction analyses (including the PCS analysis) that we conducted in this chapter using a different predictor variable (i.e., a variable other than gr_liv_area). De Cock’s data has dozens of predictive variables to choose from (we recommend picking another variable that seems to be fairly predictive of sale price). You may find the code in the 04_prediction_ls_single.qmd (or .ipynb) file in the ames_houses/dslc_documentation/ subfolder of the supplementary GitHub repository helpful.\n",
    "\n",
    "**Answer:**  \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d557c17",
   "metadata": {},
   "source": [
    "# Project Exercises\n",
    "\n",
    "## Question 1\n",
    "**Question:**  \n",
    "Predicting happiness In this project, your goal will be to predict the happiness of a country’s population4. The data that you will be using for this project comes from the World Happiness Report and can be found in the exercises/happiness/data/ folder in the supplementary GitHub repository.\n",
    "1. Read through the background information provided on the World Happiness Report website, as well as the pdf provided in the exercises/happiness/data/data_documentation/ subfolder in the supplementary GitHub repository. In the 01_cleaning.qmd (or .ipynb) file in the exercises/happiness/dslc_documentation/ subfolder, summarize anything interesting you learn about how the data was collected, what it contains, and document any questions you have (about either the background domain or the data itself).\n",
    "\n",
    "2. In the 01_cleaning.qmd (or .ipynb) code/documentation file in the relevant exercises/happiness/dslc_documentation/ subfolder, conduct data cleaning and preprocessing explorations. While we recommend writing your own cleaning/preparation function, if you are short on time, we have provided a sample function for producing one clean version of the data in the cleanHappiness.R (or .py) file in the exercises/happiness/dslc_documentation/functions/ subfolder. You may wish to filter the data to a single predictor variable that you plan to use to predict the happiness response.\n",
    "\n",
    "3. Given that the goal of the project is to predict future happiness scores, discuss how you would split the data into training, validation, and test datasets (we will use the test dataset in Chapter 13). In a new prepareHappiness.R (or .py) file in the exercises/happiness/dslc_documentation/functions/ subfolder, write some code to prepare the relevant cleaned training and validation datasets (your code should use the data cleaning function from task (b)). You can source this file to load the cleaned training and validation datasets in each subsequent analysis document.\n",
    "\n",
    "4. In the 02_eda.qmd (or .ipynb) code/documentation file in the relevant exercises/happiness/dslc_documentation/ subfolder, conduct an exploratory data analysis (EDA) of the training data (feel free to just focus on the happiness variable and the single predictor variable of your choosing, both separately and in terms of their relationship with one another).\n",
    "\n",
    "5. In the 03_prediction.qmd (or .ipynb) code/documentation file in the relevant exercises/happiness/dslc_documentation/ subfolder, train the LAD and LS linear fits for predicting happiness (using your training data) based on a predictor variable of your choosing. Report the formulas for your fitted models.\n",
    "\n",
    "6. Conduct a PCS evaluation by evaluating the predictability (using your validation dataset) and stability (based on reasonable data perturbations) of your linear fits. Comment on your results.\n",
    "\n",
    "7. Train some additional linear fits for predicting happiness using different predictor variables. Compare these additional fits to your original fit based on their predictive performance on the validation dataset.\n",
    "\n",
    "\n",
    "**Answer:**  "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
