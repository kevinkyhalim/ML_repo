{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbce170d",
   "metadata": {},
   "source": [
    "# Custom Models and Training with TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ae4b1e",
   "metadata": {},
   "source": [
    "- TF is similar to NumPy but with GPU support\n",
    "- Supports distributed computing\n",
    "- Includes a kind of J-I-T compiler that allows it to optimize computations for speed and memory usage by extracting the computation graph from a Python function, optimizing it and then run it efficiently.\n",
    "- Computation graphs can be exported to a portable format so it can be trained in a TensorFlow model in one environment (e.g. Python on Linux) and run it in another (Java on Android)\n",
    "- Implements reverse-mode autodiff and has great optimizers such as RMSProp and Nadam to minimize all sots of loss functions\n",
    "\n",
    "Has many Python API including:\n",
    "- High-level deep learning API\n",
    "- Low-level deep learning API\n",
    "- Autodiff\n",
    "- Mathematics, inlcuding linear algebra and signal processing\n",
    "- i/o and preprocessing\n",
    "- Visualization with TensorBoard\n",
    "- Deployment and optimization\n",
    "- Special data structures\n",
    "- Miscellaneous"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa45486",
   "metadata": {},
   "source": [
    "TF runs on mobile devices and also supports other languages such as C++, Java, and Swift!\n",
    "\n",
    "Other notable things about TF:\n",
    "- TensorFlow Extended: Set of libraries built by Google to productionize TF projects (including tools for data validation, preprocessing, model analysis and serving)\n",
    "- TensorFlow Hub provides a way to easily download and reuse pretrained neural networks\n",
    "- TensorFlow Resources for more TF based projects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569ac661",
   "metadata": {},
   "source": [
    "## Using TF like NumPy\n",
    "\n",
    "A tensor is very similar to a NumPy `ndarray`: usually a multidimensional array, but can also hold scalar values too."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72e28f1",
   "metadata": {},
   "source": [
    "### Tensors and Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "551683d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "t = tf.constant([[1., 2., 3.], [4.,5.,6.]]) #matrix\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a59353f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 3])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea77b411",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.float32"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cb96ec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[2., 3.],\n",
       "       [5., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f2995c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
       "array([[2.],\n",
       "       [5.]], dtype=float32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[..., 1, tf.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4feb460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[11., 12., 13.],\n",
       "       [14., 15., 16.]], dtype=float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t+10 #tf.add(t,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32954237",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[ 1.,  4.,  9.],\n",
       "       [16., 25., 36.]], dtype=float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.square(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da2ca20a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[14., 32.],\n",
       "       [32., 77.]], dtype=float32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t @ tf.transpose(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20497bf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=42>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2945a5c6",
   "metadata": {},
   "source": [
    "### Tensors and NumPy\n",
    "\n",
    "Both can be used in conjunction (create a tensor from a NumPy array and vice versa, and even apply TF operations to NumPy arrays and vice versa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e550c59a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float64, numpy=array([2., 4., 5.])>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.array([2.,4.,5.])\n",
    "tf.constant(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de1f659e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4b02e44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float64, numpy=array([ 4., 16., 25.])>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.square(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f170f1c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  4.,  9.],\n",
       "       [16., 25., 36.]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.square(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac316e6e",
   "metadata": {},
   "source": [
    "### Type Conversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af105005",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "cannot compute AddV2 as input #1(zero-based) was expected to be a float tensor but is a int32 tensor [Op:AddV2] name: ",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mInvalidArgumentError\u001b[39m                      Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m2.\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m40\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ML_repo/.venv/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    155\u001b[39m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ML_repo/.venv/lib/python3.12/site-packages/tensorflow/python/framework/ops.py:6006\u001b[39m, in \u001b[36mraise_from_not_ok_status\u001b[39m\u001b[34m(e, name)\u001b[39m\n\u001b[32m   6004\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mraise_from_not_ok_status\u001b[39m(e, name) -> NoReturn:\n\u001b[32m   6005\u001b[39m   e.message += (\u001b[33m\"\u001b[39m\u001b[33m name: \u001b[39m\u001b[33m\"\u001b[39m + \u001b[38;5;28mstr\u001b[39m(name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m-> \u001b[39m\u001b[32m6006\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m core._status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mInvalidArgumentError\u001b[39m: cannot compute AddV2 as input #1(zero-based) was expected to be a float tensor but is a int32 tensor [Op:AddV2] name: "
     ]
    }
   ],
   "source": [
    "tf.constant(2.) + tf.constant(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c5c8123",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "cannot compute AddV2 as input #1(zero-based) was expected to be a float tensor but is a double tensor [Op:AddV2] name: ",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mInvalidArgumentError\u001b[39m                      Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m2.\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m40.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat64\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ML_repo/.venv/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    155\u001b[39m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ML_repo/.venv/lib/python3.12/site-packages/tensorflow/python/framework/ops.py:6006\u001b[39m, in \u001b[36mraise_from_not_ok_status\u001b[39m\u001b[34m(e, name)\u001b[39m\n\u001b[32m   6004\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mraise_from_not_ok_status\u001b[39m(e, name) -> NoReturn:\n\u001b[32m   6005\u001b[39m   e.message += (\u001b[33m\"\u001b[39m\u001b[33m name: \u001b[39m\u001b[33m\"\u001b[39m + \u001b[38;5;28mstr\u001b[39m(name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m-> \u001b[39m\u001b[32m6006\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m core._status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mInvalidArgumentError\u001b[39m: cannot compute AddV2 as input #1(zero-based) was expected to be a float tensor but is a double tensor [Op:AddV2] name: "
     ]
    }
   ],
   "source": [
    "tf.constant(2.) + tf.constant(40., dtype= tf.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ee4a4ed3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=42.0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2 = tf.constant(40., dtype=tf.float64)\n",
    "tf.constant(2.0) + tf.cast(t2, tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94da690",
   "metadata": {},
   "source": [
    "### Variables\n",
    "\n",
    "tf.Tensor values are immutable, hence we need to change it to a tf.Variable to have it changeable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "30de2a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = tf.Variable([[1.,2.,3.], [4.,5.,6.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dd6609e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee802acd",
   "metadata": {},
   "source": [
    "tf.Variable acts much like a tf.Tensor, but it can also be modified in place using `assign()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "da5a2c98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[ 2.,  4.,  6.],\n",
       "       [ 8., 10., 12.]], dtype=float32)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.assign(2*v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "81163e5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[ 2., 42.,  6.],\n",
       "       [ 8., 10., 12.]], dtype=float32)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v[0,1].assign(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a5d2e24e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[ 2., 42.,  0.],\n",
       "       [ 8., 10.,  1.]], dtype=float32)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v[:, 2]. assign([0.,1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ed20dd62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[100.,  42.,   0.],\n",
       "       [  8.,  10., 200.]], dtype=float32)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.scatter_nd_update(indices=[[0,0],[1,2]], updates = [100., 200.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "49c075d4",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'ResourceVariable' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# direct assignment will NOT work\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mv\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m = [\u001b[32m7.\u001b[39m, \u001b[32m8.\u001b[39m,\u001b[32m9.\u001b[39m]\n",
      "\u001b[31mTypeError\u001b[39m: 'ResourceVariable' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "# direct assignment will NOT work\n",
    "v[1] = [7., 8.,9.]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe23ae4",
   "metadata": {},
   "source": [
    "### Other Data Structures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a688e5d9",
   "metadata": {},
   "source": [
    "- Sparse tensors (`tf.SparseTensor`): tensors containing mostly zeros\n",
    "\n",
    "- Tensor arrays (`tf.TensorArray`): list of tensors, with fixed length but can be optionally made extensible. All tensors must have the same shape and data type!\n",
    "\n",
    "- Ragged tensors (`tf.RaggedTensor`): represents a lists of tensors, with the same rank and data type, but with varying sizes. The dimensions along which the tensor sizes vary are called the *ragged dimensions*.\n",
    "\n",
    "- String tensors: regular tensors of type `tf.string`. It represents byte strings, not Unicode strings.\n",
    "\n",
    "- Sets: represented as regular tensors (or sparse tensors). e.g. `tf.constant([[1,2], [3,4]])` represents 2 sets {1,2} and {3,4}. More generally, each set is represented by a vector in the tensor's last axis.\n",
    "\n",
    "- Queues: Store tensors across multiple steps. Offers various kinds of queues (FIFOQueue, PriorityQueue, RandomShuffleQueue, PaddingFIFOQueue [batch items of different shapes by padding]). They are all under the `tf.queue` package."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc9e8e5",
   "metadata": {},
   "source": [
    "## Customizing Models and Training Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0326a2b1",
   "metadata": {},
   "source": [
    "### Custom Loss Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2570d4a9",
   "metadata": {},
   "source": [
    "Create a function to calculate the *Huber loss* (which is already available under `tf.keras.losses.Huber` class).\n",
    "\n",
    "Recap: <br>\n",
    "Huber loss is a hybrid loss function for regression tasks that combines the best of Mean Squared Error (MSE) and Mean Absolute Error (MAE). It uses a threshold (δ) to decide when to switch between MSE-like and MAE-like behavior:\n",
    "\n",
    "- Small errors (|prediction - true| ≤ δ): Quadratic loss (like MSE).\n",
    "- Large errors (|prediction - true| > δ): Linear loss (like MAE).\n",
    "\n",
    "Advantages\n",
    "1. Robust to Outliers:\n",
    "- For large errors (> δ), it scales linearly (like MAE), reducing the impact of outliers.\n",
    "- Avoids MSE’s problem of over-penalizing large errors.\n",
    "2. Smooth Optimization:\n",
    "- Continuously differentiable (unlike MAE), making gradient-based optimization (e.g., SGD) stable near zero error.\n",
    "3. Balanced Behavior:\n",
    "- Behaves like MSE for small errors, ensuring precise predictions for accurate data.\n",
    "- Behaves like MAE for large errors, curbing outlier influence.\n",
    "\n",
    "Disadvantages\n",
    "1. Hyperparameter Tuning (δ):\n",
    "- Choosing δ requires trial-and-error. Common values (δ = 1.0, 1.5) may not suit all tasks.\n",
    "- Too small δ: Too much like MSE (outlier-sensitive).\n",
    "- Too large δ: Too much like MAE (may underfit subtle patterns).\n",
    "2. Computational Overhead:\n",
    "- Requires conditional checks (if-else) per data point, slightly slower than MSE/MAE.\n",
    "3. Not Fully Outlier-Proof:\n",
    "- Still assigns linear penalties to extreme outliers (unlike quantile losses, which ignore them).\n",
    "\n",
    "When to Use It?\n",
    "- Outliers are present (e.g., sensor noise, corrupted data).\n",
    "- You want a balance between MSE’s precision and MAE’s robustness.\n",
    "- Differentiability is critical (e.g., deep networks with gradient-based optimization).\n",
    "\n",
    "When to Avoid It?\n",
    "- Classification tasks (use cross-entropy instead).\n",
    "- Extremely noisy datasets (consider quantile loss).\n",
    "- Minimal outliers (MSE may suffice).\n",
    "- High latency constraints (use MAE/MSE for simplicity)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebc2fe8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def huber_fn (y_true, y_pred):\n",
    "    error = y_true - y_pred\n",
    "    is_small_error = tf.abs(error) < 1\n",
    "    squared_loss = tf.square(error)\n",
    "    linear_loss = tf.abs(error) - 0.5\n",
    "    return tf.where(is_small_error, squared_loss, linear_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c966645",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x350 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# extra code – shows what the Huber loss looks like\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "plt.figure(figsize=(8, 3.5))\n",
    "z = np.linspace(-4, 4, 200)\n",
    "z_center = np.linspace(-1, 1, 200)\n",
    "plt.plot(z, huber_fn(0, z), \"b-\", linewidth=2, label=\"huber($z$)\")\n",
    "plt.plot(z, z ** 2 / 2, \"r:\", linewidth=1)\n",
    "plt.plot(z_center, z_center ** 2 / 2, \"r\", linewidth=2)\n",
    "plt.plot([-1, -1], [0, huber_fn(0., -1.)], \"k--\")\n",
    "plt.plot([1, 1], [0, huber_fn(0., 1.)], \"k--\")\n",
    "plt.gca().axhline(y=0, color='k')\n",
    "plt.gca().axvline(x=0, color='k')\n",
    "plt.text(2.1, 3.5, r\"$\\frac{1}{2}z^2$\", color=\"r\", fontsize=15)\n",
    "plt.text(3.0, 2.2, r\"$|z| - \\frac{1}{2}$\", color=\"b\", fontsize=15)\n",
    "plt.axis([-4, 4, 0, 4])\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"$z$\")\n",
    "plt.legend(fontsize=14)\n",
    "plt.title(\"Huber loss\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d560642a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevinkyhalim/ML_repo/.venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# extra code – loads, splits and scales the California housing dataset, then\n",
    "#              creates a simple Keras model\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    housing.data, housing.target.reshape(-1, 1), random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_valid_scaled = scaler.transform(X_valid)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "input_shape = X_train.shape[1:]\n",
    "\n",
    "tf.keras.utils.set_random_seed(42)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(30, activation=\"relu\", kernel_initializer=\"he_normal\",\n",
    "                          input_shape=input_shape),\n",
    "    tf.keras.layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc20ffe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=huber_fn, optimizer=\"nadam\", metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be38097a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 971us/step - loss: 0.8285 - mae: 1.1377 - val_loss: 0.4334 - val_mae: 0.6458\n",
      "Epoch 2/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 762us/step - loss: 0.3462 - mae: 0.5613 - val_loss: 0.3339 - val_mae: 0.5313\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x158906420>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe072422",
   "metadata": {},
   "source": [
    "## Saving and Loading Models That Contain Custom Components\n",
    "\n",
    "Saving the model is fine, but when loading, we need to provide a dictionary that maps the function name to the actual function!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52d2716d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_model_with_a_custom_loss.keras\")  # extra code – saving works fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bdf35781",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"my_model_with_a_custom_loss.keras\",\n",
    "                                   custom_objects={\"huber_fn\": huber_fn})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2be7ff7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 969us/step - loss: 0.3005 - mae: 0.5019 - val_loss: 0.2909 - val_mae: 0.4850\n",
      "Epoch 2/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step - loss: 0.2795 - mae: 0.4752 - val_loss: 0.2732 - val_mae: 0.4645\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x158187bc0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dbf3d030",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_huber(threshold = 1.0):\n",
    "    def huber_fn(y_true, y_pred):\n",
    "        error = y_true - y_pred\n",
    "        is_small_error = tf.abs(error) < threshold\n",
    "        squared_loss = tf.square(error) / 2\n",
    "        linear_loss  = threshold * tf.abs(error) - threshold ** 2 / 2\n",
    "        return tf.where(is_small_error, squared_loss, linear_loss)\n",
    "    return huber_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c57d209",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=create_huber(2.0), optimizer=\"nadam\", metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c0174ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 959us/step - loss: 0.2153 - mae: 0.4672 - val_loss: 0.2022 - val_mae: 0.4460\n",
      "Epoch 2/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 703us/step - loss: 0.2051 - mae: 0.4585 - val_loss: 0.1795 - val_mae: 0.4324\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x15b4339b0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1cb246c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_model_with_a_custom_loss_threshold_2.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf1da1b",
   "metadata": {},
   "source": [
    "Note that in this case, we also need to specify the `threshold` value when loading the model (note that the name to use is still \"`huber_fn`\", which is the name of the function that was given to Keras, not the name of the function that created it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3eb9b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"my_model_with_a_custom_loss_threshold_2.keras\",\n",
    "                                   custom_objects={\"huber_fn\": create_huber(2.0)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6bec6679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 953us/step - loss: 0.1997 - mae: 0.4531 - val_loss: 0.1779 - val_mae: 0.4294\n",
      "Epoch 2/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 992us/step - loss: 0.1958 - mae: 0.4483 - val_loss: 0.1742 - val_mae: 0.4251\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x15cedc530>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f40dcf",
   "metadata": {},
   "source": [
    "Another was is to create a subclass of the `tf.keras.losses.Loss` and implementing its `get_config()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2548ffbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HuberLoss (tf.keras.losses.Loss):\n",
    "    # constructor to decide how the handle\n",
    "    # the individual instance losses.\n",
    "    # By default it is \"AUTO\" = \"SUM_OVER_BATCH_SIZE\"\n",
    "    def __init__(self, threshold = 1.0, **kwargs):\n",
    "        self.threshold = threshold\n",
    "        super().__init__(**kwargs)\n",
    "    \n",
    "    # takes the labels and predictions and computes\n",
    "    # all the instance losses and returns them\n",
    "    def call (self, y_true, y_pred):\n",
    "        error = y_true - y_pred\n",
    "        is_small_error = tf.abs(error) < self.threshold\n",
    "        squared_loss = tf.square(error) / 2\n",
    "        linear_loss = self.threshold * tf.abs(error) - self.threshold**2 / 2\n",
    "        return tf.where(is_small_error, squared_loss, linear_loss)\n",
    "\n",
    "    # Returns a dictionary mapping each hyperparameter name\n",
    "    # to its value.\n",
    "    def get_config(self):\n",
    "        # calls the parent class' get_config() method\n",
    "        base_config = super().get_config()\n",
    "        # then adds the new hyperparameter to this dictionary\n",
    "        return {**base_config, \"threshold\": self.threshold}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a6241633",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevinkyhalim/ML_repo/.venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# extra code – creates another basic Keras model\n",
    "tf.keras.utils.set_random_seed(42)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(30, activation=\"relu\", kernel_initializer=\"he_normal\",\n",
    "                          input_shape=input_shape),\n",
    "    tf.keras.layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "db230f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=HuberLoss(2.), optimizer=\"nadam\", metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4be0692b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 989us/step - loss: 1.0512 - mae: 1.1438 - val_loss: 0.5086 - val_mae: 0.6718\n",
      "Epoch 2/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 728us/step - loss: 0.3170 - mae: 0.5816 - val_loss: 0.3527 - val_mae: 0.5571\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x15b6b14f0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "35bc7a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_model_with_a_custom_loss_class.keras\")  # extra code – saving works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8632c339",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"my_model_with_a_custom_loss_class.keras\",\n",
    "                                   custom_objects={\"HuberLoss\": HuberLoss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b8d6c683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2612 - mae: 0.5244 - val_loss: 0.2689 - val_mae: 0.4982\n",
      "Epoch 2/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816us/step - loss: 0.2328 - mae: 0.4929 - val_loss: 0.2207 - val_mae: 0.4657\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x157e932c0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extra code – shows that loading worked fine, the model can be used normally\n",
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a9422b88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.loss.threshold  # extra code – the treshold was loaded correctly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effd803a",
   "metadata": {},
   "source": [
    "## Custom Activation Functions, Initializers, Regularizers and Constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "36dd70ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_softplus(z):\n",
    "    return tf.math.log(1.0 + tf.exp(z))\n",
    "\n",
    "def my_glorot_initializer (shape, dtype = tf.float32):\n",
    "    stddev = tf.sqrt(2. / (shape[0] + shape[1]))\n",
    "    return tf.random.normal(shape, stddev = stddev, dtype = dtype)\n",
    "\n",
    "def my_l1_regularizer(weights):\n",
    "    return tf.reduce_sum(tf.abs(0.01 * weights))\n",
    "\n",
    "def my_positive_weights(weights):\n",
    "    return tf.where(weights < 0., tf.zeros_like(weights), weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "39db780e",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = tf.keras.layers.Dense(1, activation=my_softplus,\n",
    "                              kernel_initializer=my_glorot_initializer,\n",
    "                              kernel_regularizer=my_l1_regularizer,\n",
    "                              kernel_constraint=my_positive_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fecf1553",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyL1Regularizer(tf.keras.regularizers.Regularizer):\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "\n",
    "    def __call__(self, weights):\n",
    "        return tf.reduce_sum(tf.abs(self.factor * weights))\n",
    "\n",
    "    def get_config(self):\n",
    "        return {\"factor\": self.factor}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a82e1f",
   "metadata": {},
   "source": [
    "## Custom Metrics\n",
    "\n",
    "Take note the difference between Losses (used by gradient descent to train a model, MUST be differentiable and should not be 0 everywhere) vs metrics (used to evaluate a model, more easily interpretable and can be nondifferentiable or have zero gradients everywhere)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c8abe378",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevinkyhalim/ML_repo/.venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# extra code – once again, lets' create a basic Keras model\n",
    "tf.keras.utils.set_random_seed(42)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(30, activation=\"relu\", kernel_initializer=\"he_normal\",\n",
    "                          input_shape=input_shape),\n",
    "    tf.keras.layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a11310d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"nadam\", metrics=[create_huber(2.0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f27932a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 537us/step - huber_fn: 1.0788 - loss: 2.5942\n",
      "Epoch 2/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 578us/step - huber_fn: 0.3403 - loss: 0.7644\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x15e15caa0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extra code – train the model with our custom metric\n",
    "model.fit(X_train_scaled, y_train, epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b70306c",
   "metadata": {},
   "source": [
    "### Streaming Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8cf0fcb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.800000011920929>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision = tf.keras.metrics.Precision()\n",
    "precision([0, 1, 1, 1, 0, 1, 0, 1], [1, 1, 0, 1, 0, 1, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "afe4282b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.5>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision([0, 1, 0, 0, 1, 0, 1, 1], [1, 0, 1, 1, 0, 0, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ff2e4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.5>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the precision of up to the 2nd batch, not the 2nd batch itself1\n",
    "precision.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "be5c1592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Variable path=precision_2/true_positives, shape=(1,), dtype=float32, value=[4.]>,\n",
       " <Variable path=precision_2/false_positives, shape=(1,), dtype=float32, value=[4.]>]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0351fc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision.reset_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ffceec",
   "metadata": {},
   "source": [
    "To define your own custom streaming metric, create a subclass of the `tf.keras.metrics.Metric` class.\n",
    "\n",
    "Note that when we use metric as a function, the `update_state()` method gets called first, then the `result()` method is called, and its output is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084ffe0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HuberMetric(tf.keras.metrics.Metric):\n",
    "    def __init__(self, threshold = 1.0, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.threshold = threshold\n",
    "        self.huber_fn = create_huber(threshold)\n",
    "        # use add_weight to create the variables\n",
    "        # needed to keep track of the metric's state over multiple batches\n",
    "        self.total = self.add_weight(name=\"total\", initializer=\"zeros\")\n",
    "        self.count = self.add_weight(name=\"count\", initializer =\"zeros\")\n",
    "    \n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        sample_metrics = self.huber_fn(y_true, y_pred)\n",
    "        self.total.assign_add(tf.reduce_sum(sample_metrics))\n",
    "        self.count.assign_add(tf.cast(tf.size(y_true), tf.float32))\n",
    "\n",
    "    def result(self):\n",
    "        return self.total / self.count\n",
    "    \n",
    "    def get_config(self):\n",
    "        base_config=super().get_config()\n",
    "        return{**base_config, \"threshold\":self.threshold}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a063a2a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=14.0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = HuberMetric(2.)\n",
    "\n",
    "# total = 2 * |10 - 2| - 2²/2 = 14\n",
    "# count = 1\n",
    "# result = 14 / 1 = 14\n",
    "m(tf.constant([[2.]]), tf.constant([[10.]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6edaf078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=7.0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total = total + (|1 - 0|² / 2) + (2 * |9.25 - 5| - 2² / 2) = 14 + 7 = 21\n",
    "# count = count + 2 = 3\n",
    "# result = total / count = 21 / 3 = 7\n",
    "m(tf.constant([[0.], [5.]]), tf.constant([[1.], [9.25]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1b595472",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=7.0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fa064d76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Variable path=huber_metric/total, shape=(), dtype=float32, value=21.0>,\n",
       " <Variable path=huber_metric/count, shape=(), dtype=float32, value=3.0>]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3a9a22b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Variable path=huber_metric/total, shape=(), dtype=float32, value=0.0>,\n",
       " <Variable path=huber_metric/count, shape=(), dtype=float32, value=0.0>]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.reset_state()\n",
    "m.variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb722554",
   "metadata": {},
   "source": [
    "Check that the `HuberMetric` class works well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d371b354",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevinkyhalim/ML_repo/.venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.set_random_seed(42)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(30, activation=\"relu\", kernel_initializer=\"he_normal\",\n",
    "                          input_shape=input_shape),\n",
    "    tf.keras.layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8f9e7552",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=create_huber(2.0), optimizer=\"nadam\",\n",
    "              metrics=[HuberMetric(2.0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1a1f44d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 595us/step - huber_metric_1: 1.0512 - loss: 1.0512\n",
      "Epoch 2/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 652us/step - huber_metric_1: 0.3170 - loss: 0.3170\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x15e1e97f0>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "470dd743",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_model_with_a_custom_metric.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4216b007",
   "metadata": {},
   "source": [
    "Note that now, when we load the model back, we have to define both the loss and metric!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9ba0bb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\n",
    "    \"my_model_with_a_custom_metric.keras\",\n",
    "    custom_objects={\n",
    "        \"huber_fn\": create_huber(2.0),\n",
    "        \"HuberMetric\": HuberMetric\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a5b2425f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 624us/step - huber_metric_1: 0.2612 - loss: 0.2612\n",
      "Epoch 2/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 582us/step - huber_metric_1: 0.2328 - loss: 0.2328\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x15eed70e0>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ffaaa3",
   "metadata": {},
   "source": [
    "More simply, we could have created the class like so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a08d1c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HuberMetric(tf.keras.metrics.Mean):\n",
    "    def __init__(self, threshold=1.0, name='HuberMetric', dtype=None):\n",
    "        self.threshold = threshold\n",
    "        self.huber_fn = create_huber(threshold)\n",
    "        super().__init__(name=name, dtype=dtype)\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        metric = self.huber_fn(y_true, y_pred)\n",
    "        super(HuberMetric, self).update_state(metric, sample_weight)\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"threshold\": self.threshold}        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "935b7f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.set_random_seed(42)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(30, activation=\"relu\", kernel_initializer=\"he_normal\",\n",
    "                          input_shape=input_shape),\n",
    "    tf.keras.layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "299c0795",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.Huber(2.0), optimizer=\"nadam\",\n",
    "              weighted_metrics=[HuberMetric(2.0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8407c0be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 787us/step - HuberMetric: 1.0599 - loss: 0.5274\n",
      "Epoch 2/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 890us/step - HuberMetric: 0.3215 - loss: 0.1598\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "sample_weight = np.random.rand(len(y_train))\n",
    "history = model.fit(X_train_scaled, y_train, epochs=2,\n",
    "                    sample_weight=sample_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2abadb57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3256884217262268, np.float64(0.32568849524955656))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(history.history[\"loss\"][0],\n",
    " history.history[\"HuberMetric\"][0] * sample_weight.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e24a8292",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_model_with_a_custom_metric_v2.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d1d082a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"my_model_with_a_custom_metric_v2.keras\",\n",
    "                                   custom_objects={\"HuberMetric\": HuberMetric})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d7761778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 533us/step - HuberMetric: 0.2627 - loss: 0.2262\n",
      "Epoch 2/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 518us/step - HuberMetric: 0.2298 - loss: 0.1999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x15e5b58e0>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b0cf8b",
   "metadata": {},
   "source": [
    "## Custom Layers\n",
    "\n",
    "When wanting to build an architecture with an exotic layer which TF does not have, OR to build a very repetitive architecture, in which a particular block of layers is repeated many times and it would be convenient to treat each block as a single layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c0bd68",
   "metadata": {},
   "source": [
    "The exponential layer is sometimes used in the output layer of a regression model when the values to predict have very different scales. In fact this function is one of the standard activation functions in Keras, so it can also be used by `activation=\"exponential\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "be243e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "exponential_layer = tf.keras.layers.Lambda(lambda x: tf.exp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f8a29214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([0.36787945, 1.        , 2.7182817 ], dtype=float32)>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extra code – like all layers, it can be used as a function:\n",
    "exponential_layer(tf.constant([-1., 0., 1.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9fd4e7ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevinkyhalim/ML_repo/.venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 921us/step - loss: 1.2350 - val_loss: 0.4393\n",
      "Epoch 2/5\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 762us/step - loss: 0.6130 - val_loss: 0.4048\n",
      "Epoch 3/5\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 607us/step - loss: 0.5172 - val_loss: 0.3942\n",
      "Epoch 4/5\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 726us/step - loss: 0.4498 - val_loss: 0.3699\n",
      "Epoch 5/5\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 623us/step - loss: 0.5445 - val_loss: 0.3770\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459us/step - loss: 0.3923\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3950682282447815"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.utils.set_random_seed(42)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(30, activation=\"relu\", input_shape=input_shape),\n",
    "    tf.keras.layers.Dense(1),\n",
    "    exponential_layer\n",
    "])\n",
    "model.compile(loss=\"mse\", optimizer=\"sgd\")\n",
    "model.fit(X_train_scaled, y_train, epochs=5,\n",
    "          validation_data=(X_valid_scaled, y_valid))\n",
    "model.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f4f3f5",
   "metadata": {},
   "source": [
    "Alternatively, it's often preferable to replace the targets with the logarithm of the target and use no activation function in the output layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9a6245",
   "metadata": {},
   "source": [
    "To build a custom stateful layer, create a subclass of the `tf.keras.layers.Layer` class!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "705b8538",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDense(tf.keras.layers.Layer):\n",
    "    def __init__(self, units, activation=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.activation = tf.keras.activations.get(activation)\n",
    "    \n",
    "    # called the first time the layer is used.\n",
    "    def build (self, batch_input_shape):\n",
    "        self.kernel = self.add_weight(\n",
    "            name=\"kernel\", shape=[batch_input_shape[-1], self.units],\n",
    "            initializer=\"glorot_normal\")\n",
    "        self.bias = self.add_weight(\n",
    "            name=\"bias\", shape = [self.units], initializer = \"zeros\")\n",
    "    \n",
    "    def call(self, X):\n",
    "        return self.activation(X @ self.kernel + self.bias)\n",
    "    \n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"units\":self.units,\n",
    "                \"activation\": tf.keras.activations.serialize(self.activation)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "61cb6f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7j/0rhz18qs4d9dzfjkz9p2xlcr0000gn/T/ipykernel_1739/138382502.py:3: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 862us/step - loss: 4.2221 - val_loss: 1.7553\n",
      "Epoch 2/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701us/step - loss: 0.7143 - val_loss: 0.6906\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step - loss: 0.5624\n"
     ]
    }
   ],
   "source": [
    "# extra code – shows that a custom layer can be used normally\n",
    "tf.keras.utils.set_random_seed(42)\n",
    "model = tf.keras.Sequential([\n",
    "    MyDense(30, activation=\"relu\", input_shape=input_shape),\n",
    "    MyDense(1)\n",
    "])\n",
    "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))\n",
    "model.evaluate(X_test_scaled, y_test)\n",
    "model.save(\"my_model_with_a_custom_layer.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d289d3dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 880us/step - loss: 0.5586 - val_loss: 0.4317\n",
      "Epoch 2/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698us/step - loss: 0.4826 - val_loss: 0.4608\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x168612150>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extra code – shows how to load a model with a custom layer\n",
    "model = tf.keras.models.load_model(\"my_model_with_a_custom_layer.keras\",\n",
    "                                   custom_objects={\"MyDense\": MyDense})\n",
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fad1f36",
   "metadata": {},
   "source": [
    "For layers with multiple inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f8d824d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyMultiLayer(tf.keras.layers.Layer):\n",
    "    def call(self, X):\n",
    "        X1, X2 = X\n",
    "        print(\"X1.shape: \", X1.shape ,\" X2.shape: \", X2.shape)  # extra code\n",
    "        return X1 + X2, X1 * X2, X1 / X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ed82303d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1.shape:  (None, 2)  X2.shape:  (None, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<KerasTensor shape=(None, 2), dtype=float32, sparse=False, ragged=False, name=keras_tensor_47>,\n",
       " <KerasTensor shape=(None, 2), dtype=float32, sparse=False, ragged=False, name=keras_tensor_48>,\n",
       " <KerasTensor shape=(None, 2), dtype=float32, sparse=False, ragged=False, name=keras_tensor_49>)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extra code – tests MyMultiLayer with symbolic inputs\n",
    "inputs1 = tf.keras.layers.Input(shape=[2])\n",
    "inputs2 = tf.keras.layers.Input(shape=[2])\n",
    "MyMultiLayer()((inputs1, inputs2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8782ca46",
   "metadata": {},
   "source": [
    "Note that the `call()` method receives symbolic inputs, and it returns symbolic outputs. The shapes are only partially specified at this stage: we don't know the batch size, which is why the first dimension is `None`.\n",
    "\n",
    "We can also pass actual data to the custom layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5101cecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1.shape:  (2, 2)  X2.shape:  (2, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       " array([[ 9., 18.],\n",
       "        [ 6., 10.]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       " array([[18., 72.],\n",
       "        [ 8., 21.]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       " array([[0.5      , 0.5      ],\n",
       "        [0.5      , 2.3333333]], dtype=float32)>)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extra code – tests MyMultiLayer with actual data \n",
    "X1, X2 = np.array([[3., 6.], [2., 7.]]), np.array([[6., 12.], [4., 3.]]) \n",
    "MyMultiLayer()((X1, X2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2a350c",
   "metadata": {},
   "source": [
    "For layers that needs to have different behavior during training and testing (e.g. uses Dropout or BatchNormalization layers), then we must add a `training` argument to the `call()` method and use this argument to decide what to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5eac3ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a layer that adds Gaussian noise during training\n",
    "# (for regularization) but does nothing during testing\n",
    "\n",
    "class MyGaussianNoise(tf.keras.layers.Layer):\n",
    "    def __init__(self, stddev, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.stddev = stddev\n",
    "    \n",
    "    def call (self, X, training=False):\n",
    "        if training:\n",
    "            noise = tf.random.normal(tf.shape(X), stddev=self.stddev)\n",
    "            return X + noise\n",
    "        else:\n",
    "            return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2277c7bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7j/0rhz18qs4d9dzfjkz9p2xlcr0000gn/T/ipykernel_1739/1095381717.py:6: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 954us/step - loss: 2.7619 - val_loss: 25.1369\n",
      "Epoch 2/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 758us/step - loss: 1.3951 - val_loss: 14.9793\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step - loss: 1.1219\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.1244221925735474"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extra code – tests MyGaussianNoise\n",
    "tf.keras.utils.set_random_seed(42)\n",
    "model = tf.keras.Sequential([\n",
    "    MyGaussianNoise(stddev=1.0, input_shape=input_shape),\n",
    "    tf.keras.layers.Dense(30, activation=\"relu\",\n",
    "                          kernel_initializer=\"he_normal\"),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))\n",
    "model.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f557c0e2",
   "metadata": {},
   "source": [
    "## Custom Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "60da506d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppose we want to build a model with a ResidualBlock\n",
    "# containing a skip connection\n",
    "# The inputs go through the 1st dense layer, then through a\n",
    "# ResidualBlock composed of 2 dense layers and an addition operation\n",
    "class ResidualBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, n_layers, n_neurons, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden = [tf.keras.layers.Dense(n_neurons, activation=\"relu\",\n",
    "                                             kernel_initializer=\"he_normal\")\n",
    "                       for _ in range(n_layers)]\n",
    "\n",
    "    def call(self, inputs):\n",
    "        Z = inputs\n",
    "        for layer in self.hidden:\n",
    "            Z = layer(Z)\n",
    "        return inputs + Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "85805ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualRegressor(tf.keras.Model):\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.output_dim = output_dim\n",
    "        self.hidden1 = tf.keras.layers.Dense(30, activation=\"relu\",\n",
    "                                             kernel_initializer=\"he_normal\")\n",
    "        self.block1 = ResidualBlock(2, 30)\n",
    "        self.block2 = ResidualBlock(2, 30)\n",
    "        self.out = tf.keras.layers.Dense(output_dim)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        Z = self.hidden1(inputs)\n",
    "        for _ in range(1 + 3):\n",
    "            Z = self.block1(Z)\n",
    "        Z = self.block2(Z)\n",
    "        return self.out(Z)\n",
    "\n",
    "    # extra code - to be able to save and load the model below\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"output_dim\": self.output_dim}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1b6d10e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 726us/step - loss: 123.5810\n",
      "Epoch 2/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698us/step - loss: 1.5416\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532us/step - loss: 1.1640\n"
     ]
    }
   ],
   "source": [
    "# extra code – shows that the model can be used normally\n",
    "tf.keras.utils.set_random_seed(42)\n",
    "model = ResidualRegressor(1)\n",
    "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
    "history = model.fit(X_train_scaled, y_train, epochs=2)\n",
    "score = model.evaluate(X_test_scaled, y_test)\n",
    "model.save(\"my_custom_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "941898d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 975us/step - loss: 1.0556\n",
      "Epoch 2/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 708us/step - loss: 0.9670\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.700629 ],\n",
       "       [1.111954 ],\n",
       "       [3.8838222]], dtype=float32)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extra code – the model can be loaded and you can continue training or use it\n",
    "#              to make predictions\n",
    "model = tf.keras.models.load_model(\n",
    "    \"my_custom_model.keras\",\n",
    "    custom_objects={\"ResidualRegressor\": ResidualRegressor}\n",
    ")\n",
    "history = model.fit(X_train_scaled, y_train, epochs=2)\n",
    "model.predict(X_test_scaled[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "499c70cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the model via sequential API\n",
    "tf.keras.utils.set_random_seed(42)\n",
    "block1 = ResidualBlock(2, 30)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(30, activation=\"relu\",\n",
    "                          kernel_initializer=\"he_normal\"),\n",
    "    block1, block1, block1, block1,\n",
    "    ResidualBlock(2, 30),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f23bf04",
   "metadata": {},
   "source": [
    "# Losses and Metrics Based on Model Internals\n",
    "\n",
    "When we want to define the losses based on other parts of the model, such as the weights / activation of its hidden layers (useful for regularization purposes / to monitor some internal aspect of the model).\n",
    "\n",
    "To define this, we need to compute it based on any part of the model you want, then pass the result to the `add_loss()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7d972ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReconstructingRegressor(tf.keras.Model):\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden = [tf.keras.layers.Dense(30, activation=\"relu\",\n",
    "                                             kernel_initializer=\"he_normal\")\n",
    "                       for _ in range(5)]\n",
    "        self.out = tf.keras.layers.Dense(output_dim)\n",
    "\n",
    "    def build(self, batch_input_shape):\n",
    "        n_inputs = batch_input_shape[-1]\n",
    "        self.reconstruct = tf.keras.layers.Dense(n_inputs)\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        Z = inputs\n",
    "        for layer in self.hidden:\n",
    "            Z = layer(Z)\n",
    "        reconstruction = self.reconstruct(Z)\n",
    "        recon_loss = tf.reduce_mean(tf.square(reconstruction - inputs))\n",
    "        self.add_loss(0.05 * recon_loss)\n",
    "        return self.out(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ec9fc03c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 795us/step - loss: 1.1051\n",
      "Epoch 2/5\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 685us/step - loss: 0.5082\n",
      "Epoch 3/5\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698us/step - loss: 0.4392\n",
      "Epoch 4/5\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 668us/step - loss: 0.3985\n",
      "Epoch 5/5\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 669us/step - loss: 0.3805\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 544us/step\n"
     ]
    }
   ],
   "source": [
    "# extra code\n",
    "tf.keras.utils.set_random_seed(42)\n",
    "model = ReconstructingRegressor(1)\n",
    "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
    "history = model.fit(X_train_scaled, y_train, epochs=5)\n",
    "y_pred = model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db72771",
   "metadata": {},
   "source": [
    "# Computing Gradients using Autodiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6b0aec2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(w1, w2):\n",
    "    return 3 * w1 ** 2 + 2 * w1 * w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1a4059b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36.000003007075065"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1, w2 = 5, 3\n",
    "eps = 1e-6\n",
    "(f(w1 + eps, w2) - f(w1, w2)) / eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "9d78fa81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.000000003174137"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(f(w1, w2 + eps) - f(w1, w2)) / eps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7974afb0",
   "metadata": {},
   "source": [
    "Rather than calling `f()` at least once per parameter, we can instead use reverse-mode autodiff!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1007e027",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1, w2 = tf.Variable(5.), tf.Variable(3.)\n",
    "\n",
    "# create the tf.GradientTape context to automatically\n",
    "# record every operation that involves a variable\n",
    "with tf.GradientTape() as tape:\n",
    "    z = f(w1, w2)\n",
    "\n",
    "# compute the gradients of the result Z with regards\n",
    "# to both variables\n",
    "gradients = tape.gradient(z, [w1, w2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b94444e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=36.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=10.0>]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0f5f36e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A non-persistent GradientTape can only be used to compute one set of gradients (or jacobians)\n"
     ]
    }
   ],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    z = f(w1, w2)\n",
    "\n",
    "dz_dw1 = tape.gradient(z, w1)  # returns tensor 36.0\n",
    "try:\n",
    "    dz_dw2 = tape.gradient(z, w2)  # raises a RuntimeError!\n",
    "except RuntimeError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7150621e",
   "metadata": {},
   "source": [
    "To call the `gradient()` more than once, use the `persistent=True` argument. Then delete it once you are done to free resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "de9d9086",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    z = f(w1, w2)\n",
    "\n",
    "dz_dw1 = tape.gradient(z, w1)  # returns tensor 36.0\n",
    "dz_dw2 = tape.gradient(z, w2)  # returns tensor 10.0, works fine now!\n",
    "del tape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "43a5c43f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=36.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=10.0>)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dz_dw1, dz_dw2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0860fa8",
   "metadata": {},
   "source": [
    "By default, the tape will only trakc operations involving VARIABLES, so using constants will not work, as seen below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "5e27465a",
   "metadata": {},
   "outputs": [],
   "source": [
    "c1, c2 = tf.constant(5.), tf.constant(3.)\n",
    "with tf.GradientTape() as tape:\n",
    "    z = f(c1, c2)\n",
    "\n",
    "gradients = tape.gradient(z, [c1, c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "5db6022a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdcf0a7",
   "metadata": {},
   "source": [
    "However, you can force the tape to watch any tensors you like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "7537e2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(c1)\n",
    "    tape.watch(c2)\n",
    "    z = f(c1, c2)\n",
    "\n",
    "gradients = tape.gradient(z, [c1, c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "312340fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=36.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=10.0>]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "23805e9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=136.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=30.0>]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extra code – if given a vector, tape.gradient() will compute the gradient of\n",
    "#              the vector's sum.\n",
    "with tf.GradientTape() as tape:\n",
    "    z1 = f(w1, w2 + 2.)\n",
    "    z2 = f(w1, w2 + 5.)\n",
    "    z3 = f(w1, w2 + 7.)\n",
    "\n",
    "tape.gradient([z1, z2, z3], [w1, w2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "1d9021c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=136.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=30.0>]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extra code – shows that we get the same result as the previous cell\n",
    "with tf.GradientTape() as tape:\n",
    "    z1 = f(w1, w2 + 2.)\n",
    "    z2 = f(w1, w2 + 5.)\n",
    "    z3 = f(w1, w2 + 7.)\n",
    "    z = z1 + z2 + z3\n",
    "\n",
    "tape.gradient(z, [w1, w2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d05a4a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra code – shows how to compute the jacobians and the hessians\n",
    "with tf.GradientTape(persistent=True) as hessian_tape:\n",
    "    with tf.GradientTape() as jacobian_tape:\n",
    "        z = f(w1, w2)\n",
    "    jacobians = jacobian_tape.gradient(z, [w1, w2])\n",
    "hessians = [hessian_tape.gradient(jacobian, [w1, w2])\n",
    "            for jacobian in jacobians]\n",
    "del hessian_tape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e0f430bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=36.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=10.0>]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jacobians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "8ecaec02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[<tf.Tensor: shape=(), dtype=float32, numpy=6.0>,\n",
       "  <tf.Tensor: shape=(), dtype=float32, numpy=2.0>],\n",
       " [<tf.Tensor: shape=(), dtype=float32, numpy=2.0>, None]]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hessians"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0def1306",
   "metadata": {},
   "source": [
    "To avoid backpropagation through some part of the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "492dc8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(w1, w2):\n",
    "    return 3 * w1 ** 2 + tf.stop_gradient(2 * w1 * w2)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    z = f(w1, w2)  # same result as without stop_gradient()\n",
    "\n",
    "gradients = tape.gradient(z, [w1, w2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "05ee572c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=30.0>, None]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf9ea89",
   "metadata": {},
   "source": [
    "Numerical issue when computing gradients where the result is more than 32-bit floats can handle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "042f7873",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=inf>]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.Variable(1e-50)\n",
    "with tf.GradientTape() as tape:\n",
    "    z = tf.sqrt(x)\n",
    "\n",
    "tape.gradient(z, [x])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bce26c1",
   "metadata": {},
   "source": [
    "To solve this, it's often a good idea to add a tiny value to x when computing its square root."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "13746122",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=30.0>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.log(tf.exp(tf.constant(30., dtype=tf.float32)) + 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "04d707b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(1,), dtype=float32, numpy=array([nan], dtype=float32)>]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.Variable([1.0e30])\n",
    "with tf.GradientTape() as tape:\n",
    "    z = my_softplus(x)\n",
    "\n",
    "tape.gradient(z, [x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "c6c4a6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_softplus(z):\n",
    "    return tf.math.log(1 + tf.exp(-tf.abs(z))) + tf.maximum(0., z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fb1df9",
   "metadata": {},
   "source": [
    "Here is the proof that this equation is equal to log(1 + exp(_z_)):\n",
    "* softplus(_z_) = log(1 + exp(_z_))\n",
    "* softplus(_z_) = log(1 + exp(_z_)) - log(exp(_z_)) + log(exp(_z_)) ; **just adding and subtracting the same value**\n",
    "* softplus(_z_) = log\\[(1 + exp(_z_)) / exp(_z_)\\] + log(exp(_z_)) ; **since log(_a_) - log(_b_) = log(_a_ / _b_)**\n",
    "* softplus(_z_) = log\\[(1 + exp(_z_)) / exp(_z_)\\] + _z_ ; **since log(exp(_z_)) = _z_**\n",
    "* softplus(_z_) = log\\[1 / exp(_z_) + exp(_z_) / exp(_z_)\\] + _z_ ; **since (1 + _a_) / _b_ = 1 / _b_ + _a_ / _b_**\n",
    "* softplus(_z_) = log\\[exp(–_z_) + 1\\] + _z_ ; **since 1 / exp(_z_) = exp(–z), and exp(_z_) / exp(_z_) = 1**\n",
    "* softplus(_z_) = softplus(–_z_) + _z_ ; **we recognize the definition at the top, but with –_z_**\n",
    "* softplus(_z_) = softplus(–|_z_|) + max(0, _z_) ; **if you consider both cases, _z_ < 0 or _z_ ≥ 0, you will see that this works**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "c5d96d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.custom_gradient\n",
    "def my_softplus(z):\n",
    "    def my_softplus_gradients(grads):  # grads = backprop'ed from upper layers\n",
    "        return grads * (1 - 1 / (1 + tf.exp(z)))  # stable grads of softplus\n",
    "\n",
    "    result = tf.math.log(1 + tf.exp(-tf.abs(z))) + tf.maximum(0., z)\n",
    "    return result, my_softplus_gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "33ef6e10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1000.], dtype=float32)>,\n",
       " [<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extra code – shows that the function is now stable, as well as its gradients\n",
    "x = tf.Variable([1000.])\n",
    "with tf.GradientTape() as tape:\n",
    "    z = my_softplus(x)\n",
    "\n",
    "z, tape.gradient(z, [x])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a429e2b1",
   "metadata": {},
   "source": [
    "# Custom Training Loops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51650d91",
   "metadata": {},
   "source": [
    "Unless you are laerning or really need the extra flexibility, you should prefer using the fit() method rather than implementing your own training loop, especially if you work in a team!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "3ccd0ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.set_random_seed(42)  # extra code – to ensure reproducibility\n",
    "l2_reg = tf.keras.regularizers.l2(0.05)\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(30, activation=\"relu\", kernel_initializer=\"he_normal\",\n",
    "                          kernel_regularizer=l2_reg),\n",
    "    tf.keras.layers.Dense(1, kernel_regularizer=l2_reg)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "7d5dd3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_batch(X, y, batch_size=32):\n",
    "    idx = np.random.randint(len(X), size=batch_size)\n",
    "    return X[idx], y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "560c3de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_status_bar(step, total, loss, metrics=None):\n",
    "    metrics = \" - \".join([f\"{m.name}: {m.result():.4f}\"\n",
    "                          for m in [loss] + (metrics or [])])\n",
    "    end = \"\" if step < total else \"\\n\"\n",
    "    print(f\"\\r{step}/{total} - \" + metrics, end=end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "d70006c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "3b79a9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 5\n",
    "batch_size = 32\n",
    "n_steps = len(X_train) // batch_size\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
    "loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "mean_loss = tf.keras.metrics.Mean()\n",
    "metrics = [tf.keras.metrics.MeanAbsoluteError()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1086f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "362/362 - mean: 3.5419 - mean_absolute_error: 0.6640\n",
      "Epoch 2/5\n",
      "362/362 - mean: 1.8693 - mean_absolute_error: 0.5431\n",
      "Epoch 3/5\n",
      "362/362 - mean: 1.1428 - mean_absolute_error: 0.5030\n",
      "Epoch 4/5\n",
      "362/362 - mean: 0.8501 - mean_absolute_error: 0.4977\n",
      "Epoch 5/5\n",
      "362/362 - mean: 0.7280 - mean_absolute_error: 0.5014\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, n_epochs + 1):\n",
    "    print(f\"Epoch {epoch}/{n_epochs}\")\n",
    "    for step in range(1, n_steps + 1):\n",
    "        X_batch, y_batch = random_batch(X_train_scaled, y_train)\n",
    "        with tf.GradientTape() as tape:\n",
    "            # make prediction for one batch\n",
    "            y_pred = model(X_batch, training=True)\n",
    "            # compute the mean loss over the batch\n",
    "            main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
    "            # sum the lossess since the regularization loss\n",
    "            # are already reduced to a single scalar\n",
    "            loss = tf.add_n([main_loss] + model.losses)\n",
    "\n",
    "        # ask the tape to compute the gradients of the loss\n",
    "        # with regard to each trainable variable\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        # apply them to the optimizer to perform gradient descent step\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "        # extra code – if your model has variable constraints\n",
    "        for variable in model.variables:\n",
    "            if variable.constraint is not None:\n",
    "                variable.assign(variable.constraint(variable))\n",
    "\n",
    "        # update the mean loss and the metric\n",
    "        mean_loss(loss)\n",
    "        for metric in metrics:\n",
    "            metric(y_batch, y_pred)\n",
    "\n",
    "        #display the status bar\n",
    "        print_status_bar(step, n_steps, mean_loss, metrics)\n",
    "\n",
    "    # at the end of each epoch, reset the states of the mean loss and metrics\n",
    "    for metric in [mean_loss] + metrics:\n",
    "        metric.reset_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "08e19835",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[126]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtqdm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnotebook\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m trange\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcollections\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OrderedDict\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mtrange\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mAll epochs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m epochs:\n\u001b[32m      6\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m epochs:\n\u001b[32m      7\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m trange(\u001b[32m1\u001b[39m, n_steps + \u001b[32m1\u001b[39m, desc=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m steps:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ML_repo/.venv/lib/python3.12/site-packages/tqdm/notebook.py:312\u001b[39m, in \u001b[36mtnrange\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    310\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtnrange\u001b[39m(*args, **kwargs):\n\u001b[32m    311\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Shortcut for `tqdm.notebook.tqdm(range(*args), **kwargs)`.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m312\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtqdm_notebook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ML_repo/.venv/lib/python3.12/site-packages/tqdm/notebook.py:234\u001b[39m, in \u001b[36mtqdm_notebook.__init__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    232\u001b[39m unit_scale = \u001b[32m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.unit_scale \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.unit_scale \u001b[38;5;129;01mor\u001b[39;00m \u001b[32m1\u001b[39m\n\u001b[32m    233\u001b[39m total = \u001b[38;5;28mself\u001b[39m.total * unit_scale \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.total \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.total\n\u001b[32m--> \u001b[39m\u001b[32m234\u001b[39m \u001b[38;5;28mself\u001b[39m.container = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstatus_printer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdesc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mncols\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    235\u001b[39m \u001b[38;5;28mself\u001b[39m.container.pbar = proxy(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m    236\u001b[39m \u001b[38;5;28mself\u001b[39m.displayed = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ML_repo/.venv/lib/python3.12/site-packages/tqdm/notebook.py:108\u001b[39m, in \u001b[36mtqdm_notebook.status_printer\u001b[39m\u001b[34m(_, total, desc, ncols)\u001b[39m\n\u001b[32m     99\u001b[39m \u001b[38;5;66;03m# Fallback to text bar if there's no total\u001b[39;00m\n\u001b[32m    100\u001b[39m \u001b[38;5;66;03m# DEPRECATED: replaced with an 'info' style bar\u001b[39;00m\n\u001b[32m    101\u001b[39m \u001b[38;5;66;03m# if not total:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    105\u001b[39m \n\u001b[32m    106\u001b[39m \u001b[38;5;66;03m# Prepare IPython progress bar\u001b[39;00m\n\u001b[32m    107\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m IProgress \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# #187 #451 #558 #872\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m108\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(WARN_NOIPYW)\n\u001b[32m    109\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m total:\n\u001b[32m    110\u001b[39m     pbar = IProgress(\u001b[38;5;28mmin\u001b[39m=\u001b[32m0\u001b[39m, \u001b[38;5;28mmax\u001b[39m=total)\n",
      "\u001b[31mImportError\u001b[39m: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html"
     ]
    }
   ],
   "source": [
    "# extra code – shows how to use the tqdm package to display nice progress bars\n",
    "\n",
    "from tqdm.notebook import trange\n",
    "from collections import OrderedDict\n",
    "with trange(1, n_epochs + 1, desc=\"All epochs\") as epochs:\n",
    "    for epoch in epochs:\n",
    "        with trange(1, n_steps + 1, desc=f\"Epoch {epoch}/{n_epochs}\") as steps:\n",
    "            for step in steps:\n",
    "                X_batch, y_batch = random_batch(X_train_scaled, y_train)\n",
    "                with tf.GradientTape() as tape:\n",
    "                    y_pred = model(X_batch)\n",
    "                    main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
    "                    loss = tf.add_n([main_loss] + model.losses)\n",
    "\n",
    "                gradients = tape.gradient(loss, model.trainable_variables)\n",
    "                optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "                for variable in model.variables:\n",
    "                    if variable.constraint is not None:\n",
    "                        variable.assign(variable.constraint(variable))\n",
    "\n",
    "                status = OrderedDict()\n",
    "                mean_loss(loss)\n",
    "                status[\"loss\"] = mean_loss.result().numpy()\n",
    "                for metric in metrics:\n",
    "                    metric(y_batch, y_pred)\n",
    "                    status[metric.name] = metric.result().numpy()\n",
    "\n",
    "                steps.set_postfix(status)\n",
    "\n",
    "        for metric in [mean_loss] + metrics:\n",
    "            metric.reset_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec64bfe",
   "metadata": {},
   "source": [
    "# TensorFlow Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "e21fd5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cube(x):\n",
    "    return x ** 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "bb63438f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cube (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "3dcc03a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=8.0>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cube(tf.constant(2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "bfd87457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.eager.polymorphic_function.polymorphic_function.Function at 0x17d751220>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_cube = tf.function(cube)\n",
    "tf_cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "3bba807e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=8>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_cube(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "5cf545e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=8.0>"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_cube(tf.constant(2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "f0d928b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def tf_cube(x):\n",
    "    return x ** 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "853a7e10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_cube.python_function(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b6b1c5",
   "metadata": {},
   "source": [
    "Basically TensorFlow optimizes the computation graph, pruning unused nodes, simplifying expressions, etc. So if you want to boost a Python function, just transform it into a TF function!\n",
    "\n",
    "When writing custom loss function, metric, layer or any other functions, and you use it in a Keras model, Keras automatically converts the function into a TF function! And if you want Keras to use XLA, just set `jit_compile=True` when calling the `compile()` method!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818be42e",
   "metadata": {},
   "source": [
    "## AutoGraph and Tracing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39d39bb",
   "metadata": {},
   "source": [
    "Basically understanding how to convert python code to TF compatible code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "167c3372",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def add_10(x):\n",
    "    for i in range(10):\n",
    "        x += 1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "3ddbe7b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=15>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_10(tf.constant(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "4ce70541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'x' type=Placeholder>,\n",
       " <tf.Operation 'add/y' type=Const>,\n",
       " <tf.Operation 'add' type=AddV2>,\n",
       " <tf.Operation 'add_1/y' type=Const>,\n",
       " <tf.Operation 'add_1' type=AddV2>,\n",
       " <tf.Operation 'add_2/y' type=Const>,\n",
       " <tf.Operation 'add_2' type=AddV2>,\n",
       " <tf.Operation 'add_3/y' type=Const>,\n",
       " <tf.Operation 'add_3' type=AddV2>,\n",
       " <tf.Operation 'add_4/y' type=Const>,\n",
       " <tf.Operation 'add_4' type=AddV2>,\n",
       " <tf.Operation 'add_5/y' type=Const>,\n",
       " <tf.Operation 'add_5' type=AddV2>,\n",
       " <tf.Operation 'add_6/y' type=Const>,\n",
       " <tf.Operation 'add_6' type=AddV2>,\n",
       " <tf.Operation 'add_7/y' type=Const>,\n",
       " <tf.Operation 'add_7' type=AddV2>,\n",
       " <tf.Operation 'add_8/y' type=Const>,\n",
       " <tf.Operation 'add_8' type=AddV2>,\n",
       " <tf.Operation 'add_9/y' type=Const>,\n",
       " <tf.Operation 'add_9' type=AddV2>,\n",
       " <tf.Operation 'Identity' type=Identity>]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_10.get_concrete_function(tf.constant(5)).graph.get_operations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "c471f87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra code – shows how to use tf.while_loop (usually @tf.function is simpler)\n",
    "@tf.function\n",
    "def add_10(x):\n",
    "    condition = lambda i, x: tf.less(i, 10)\n",
    "    body = lambda i, x: (tf.add(i, 1), tf.add(x, 1))\n",
    "    final_i, final_x = tf.while_loop(condition, body, [tf.constant(0), x])\n",
    "    return final_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "6026112b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=15>"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_10(tf.constant(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "eaf96806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'x' type=Placeholder>,\n",
       " <tf.Operation 'Const' type=Const>,\n",
       " <tf.Operation 'while/maximum_iterations' type=Const>,\n",
       " <tf.Operation 'while/loop_counter' type=Const>,\n",
       " <tf.Operation 'while' type=StatelessWhile>,\n",
       " <tf.Operation 'Identity' type=Identity>]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_10.get_concrete_function(tf.constant(5)).graph.get_operations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "33e87061",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def add_10(x):\n",
    "    for i in tf.range(10):\n",
    "        x = x + 1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "90bab770",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'x' type=Placeholder>,\n",
       " <tf.Operation 'range/start' type=Const>,\n",
       " <tf.Operation 'range/limit' type=Const>,\n",
       " <tf.Operation 'range/delta' type=Const>,\n",
       " <tf.Operation 'range' type=Range>,\n",
       " <tf.Operation 'sub' type=Sub>,\n",
       " <tf.Operation 'floordiv' type=FloorDiv>,\n",
       " <tf.Operation 'mod' type=FloorMod>,\n",
       " <tf.Operation 'zeros_like' type=Const>,\n",
       " <tf.Operation 'NotEqual' type=NotEqual>,\n",
       " <tf.Operation 'Cast' type=Cast>,\n",
       " <tf.Operation 'add' type=AddV2>,\n",
       " <tf.Operation 'zeros_like_1' type=Const>,\n",
       " <tf.Operation 'Maximum' type=Maximum>,\n",
       " <tf.Operation 'while/maximum_iterations' type=Const>,\n",
       " <tf.Operation 'while/loop_counter' type=Const>,\n",
       " <tf.Operation 'while' type=StatelessWhile>,\n",
       " <tf.Operation 'Identity' type=Identity>]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_10.get_concrete_function(tf.constant(0)).graph.get_operations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e090cffb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
