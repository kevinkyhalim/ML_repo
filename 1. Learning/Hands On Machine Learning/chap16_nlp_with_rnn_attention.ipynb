{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26ece4cf",
   "metadata": {},
   "source": [
    "# Natural Language Processing with RNNs and Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b6776e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "assert sys.version_info >= (3, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ea94433",
   "metadata": {},
   "outputs": [],
   "source": [
    "from packaging import version\n",
    "import tensorflow as tf\n",
    "\n",
    "assert version.parse(tf.__version__) >= version.parse(\"2.8.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "620e2871",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.19.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7dba6c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rc('font', size=14)\n",
    "plt.rc('axes', labelsize=14, titlesize=14)\n",
    "plt.rc('legend', fontsize=14)\n",
    "plt.rc('xtick', labelsize=10)\n",
    "plt.rc('ytick', labelsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc1b0c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "IMAGES_PATH = Path() / \"images\" / \"nlp\"\n",
    "IMAGES_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = IMAGES_PATH / f\"{fig_id}.{fig_extension}\"\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "079a97e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not tf.config.list_physical_devices('GPU'):\n",
    "    print(\"No GPU was detected. Neural nets can be very slow without a GPU.\")\n",
    "    if \"google.colab\" in sys.modules:\n",
    "        print(\"Go to Runtime > Change runtime and select a GPU hardware \"\n",
    "              \"accelerator.\")\n",
    "    if \"kaggle_secrets\" in sys.modules:\n",
    "        print(\"Go to Settings > Accelerator and select GPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92e095e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.9.2'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8b0832",
   "metadata": {},
   "source": [
    "Seems that a lot of the code in this notebook has to be run on Keras 2, so refer to the link below for the code implementation. The codes written here may not necessarily work.\n",
    "\n",
    "https://colab.research.google.com/github/ageron/handson-ml3/blob/main/16_nlp_with_rnns_and_attention.ipynb#scrollTo=EisVmaH56dmU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8925edca",
   "metadata": {},
   "source": [
    "## Generating Shakespearean Text Using a Character RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7a1f8be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://homl.info/shakespeare\n",
      "\u001b[1m1115394/1115394\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "shakespeare_url = \"https://homl.info/shakespeare\"  # shortcut URL\n",
    "filepath = tf.keras.utils.get_file(\"shakespeare.txt\", shakespeare_url)\n",
    "with open(filepath) as f:\n",
    "    shakespeare_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c331a248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n"
     ]
    }
   ],
   "source": [
    "# extra code – shows a short text sample\n",
    "print(shakespeare_text[:80])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c88c5fe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n !$&',-.3:;?abcdefghijklmnopqrstuvwxyz\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extra code – shows all 39 distinct characters (after converting to lower case)\n",
    "\"\".join(sorted(set(shakespeare_text.lower())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9181b599",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-13 14:22:59.624917: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M4\n",
      "2025-06-13 14:22:59.626979: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 24.00 GB\n",
      "2025-06-13 14:22:59.627026: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 8.00 GB\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1749795779.627837 6202607 pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1749795779.628056 6202607 pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "text_vec_layer = tf.keras.layers.TextVectorization(split=\"character\",\n",
    "                                                   standardize=\"lower\")\n",
    "text_vec_layer.adapt([shakespeare_text])\n",
    "encoded = text_vec_layer([shakespeare_text])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5890b897",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded -= 2 # drop tokens 0 (pad) and 1 (unknown)\n",
    "n_tokens = text_vec_layer.vocabulary_size()\n",
    "dataset_size = len(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c789e8f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1115394"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a10117",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_dataset(sequence, length, shuffle=False, seed=None, batch_size=32):\n",
    "    ds = tf.data.Dataset.from_tensor_slices(sequence)\n",
    "    ds = ds.window(length + 1, shift = 1, drop_remainder=True)\n",
    "    ds = ds.flat_map (lambda window_ds: window_ds.batch(length+1))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=100000, seed=seed)\n",
    "    ds = ds.batch(batch_size)\n",
    "    # returns input / output pairs\n",
    "    return ds.map(lambda window: (window[:, :-1], window[:,1:])).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c908bb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "length = 100\n",
    "tf.random.set_seed(42)\n",
    "train_set = to_dataset(encoded[:1000000], length = length, shuffle = True, seed = 42)\n",
    "valid_set = to_dataset(encoded[1000000:1060000], length = length)\n",
    "test_set = to_dataset(encoded[1060000:], length = length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e0be61f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-13 14:48:57.458412: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(<tf.Tensor: shape=(1, 4), dtype=int64, numpy=array([[ 4,  5,  2, 23]])>,\n",
       "  <tf.Tensor: shape=(1, 4), dtype=int64, numpy=array([[ 5,  2, 23,  3]])>)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extra code – a simple example using to_dataset()\n",
    "# There's just one sample in this dataset: the input represents \"to b\" and the\n",
    "# output represents \"o be\"\n",
    "list(to_dataset(text_vec_layer([\"To be\"])[0], length=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed6621b",
   "metadata": {},
   "source": [
    "### Building and Training the Char-RNN Model\n",
    "\n",
    "The model below will run around 1 - 2 hours!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245a6d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)  # extra code – ensures reproducibility on CPU\n",
    "model = tf.keras.Sequential([\n",
    "    # Encode the characters IDs\n",
    "    # note that input to Embedding layer are 2D tensors, but outputs are 3D tensors\n",
    "    tf.keras.layers.Embedding(input_dim=n_tokens, output_dim=16),\n",
    "    tf.keras.layers.GRU(128, return_sequences=True),\n",
    "    # set the neuron to have n_tokens since we want to output a \n",
    "    # probability for each possible character.\n",
    "    tf.keras.layers.Dense(n_tokens, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model_ckpt = tf.keras.callbacks.ModelCheckpoint(\n",
    "    \"my_shakespeare_model.keras\", monitor=\"val_accuracy\", save_best_only=True)\n",
    "history = model.fit(train_set, validation_data=valid_set, epochs=10,\n",
    "                    callbacks=[model_ckpt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a3224e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "shakespeare_model = tf.keras.Sequential([\n",
    "    text_vec_layer,\n",
    "    tf.keras.layers.Lambda(lambda X: X - 2),  # no <PAD> or <UNK> tokens\n",
    "    model\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fad23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra code – downloads a pretrained model\n",
    "url = \"https://github.com/ageron/data/raw/main/shakespeare_model.tgz\"\n",
    "path = tf.keras.utils.get_file(\"shakespeare_model.tgz\", url)\n",
    "if \"_extracted\" in path:\n",
    "    model_path = Path(path) / \"shakespeare_model.keras\"\n",
    "else:\n",
    "    model_path = Path(path).with_name(\"shakespeare_model.keras\")\n",
    "shakespeare_model = tf.keras.models.load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096b8ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba = shakespeare_model.predict([\"To be or not to b\"])[0, -1]\n",
    "y_pred = tf.argmax(y_proba)  # choose the most probable character ID\n",
    "text_vec_layer.get_vocabulary()[y_pred + 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c33dde",
   "metadata": {},
   "source": [
    "### Generating Fake Shakespearean Text\n",
    "\n",
    "When feeding the model some text, we can have it iteratively generate the next most likely next letter (*greedy decoding*). However, since this will in practice lead to the same words being repeated over and over again, we can sample the next character randomly using tensorflow's `tf.random.categorical()` function. The function samples random class indices give the class log probabilities(logits).\n",
    "\n",
    "We can then divide the logits by a *temperature*, where a close to 0 value will favor high-probability characters, while a high temperature gives all characters an equal probability.\n",
    "\n",
    "To generate more convincing text, a common technique is to sample only from the top *k* characters, or only from the smallest set of top characters whose total probability exceeds some threshold (*nucleus sampling*).\n",
    "\n",
    "Alternatively we can try using *beam search* or use ore GRU layers and more neurons per layer, training for longer and adding some regularization if needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328fe959",
   "metadata": {},
   "source": [
    "### Stateful RNN\n",
    "\n",
    "in *stateless* RNNs, at each training iteration the model starts with a hidden state full of zeros, then updates this state at ech time step, and after the last time step, it throws it away as it is notneeded anymore.\n",
    "\n",
    "*Stateful* preserves this final state after processing a training batch and uses it as the initial state for the next training batch, allowing the model to learn long-term patterns despite only backpropagating through short sequences.\n",
    "\n",
    "This ONLY works if each input sequence in a batch starts EXACTLY where the corresponding sequence in the previous batch left off. So when creating the dataset, we must use\n",
    "- `shift=length` (instead of `shift=1`)\n",
    "- must NOT call the `shuffle()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d303b0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_dataset_for_stateful_rnn(sequence, length):\n",
    "    ds = tf.data.Dataset.from_tensor_slices(sequence)\n",
    "    ds = ds.window(length + 1, shift = length, drop_remainder=True)\n",
    "    ds = ds.flat_map(lambda window: window.batch(length+1)).batch(1)\n",
    "    return ds.map(lambda window: (window[:, :-1], window[:, 1:])).prefetch(1)\n",
    "\n",
    "stateful_train_set = to_dataset_for_stateful_rnn(encoded[:1000000], length)\n",
    "stateful_valid_set = to_dataset_for_stateful_rnn(encoded[1000000:1060000], length)\n",
    "stateful_test_set = to_dataset_for_stateful_rnn(encoded[1060000:], length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866ef29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim = n_tokens, output_dim = 16,\n",
    "                              batch_input_shape=[1, None]),\n",
    "                              tf.keras.layers.GRU(128, return_sequences=True, stateful=True),\n",
    "                              tf.keras.layers.Dense(n_tokens, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2ad86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResetStatesCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_begin(self, epoch, logs):\n",
    "        self.model.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca25885a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer='nadam',\n",
    "              metrics=[\"accuracy\"])\n",
    "history = model.fit(stateful_train_set, validation_data=stateful_valid_set,\n",
    "                    epochs = 10, callbacks=[ResetStatesCallback(), model_ckpt])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5d9e3f",
   "metadata": {},
   "source": [
    "## Sentiment Analysis\n",
    "\n",
    "A form of text classification.\n",
    "\n",
    "Unlike the previous model, we will preprocess the text by chopping it into words instead of characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6e0a92a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "raw_train_set, raw_valid_set, raw_test_set = tfds.load(\n",
    "    name=\"imdb_reviews\",\n",
    "    split=[\"train[:90%]\", \"train[90%:]\", \"test\"],\n",
    "    as_supervised=True\n",
    ")\n",
    "tf.random.set_seed(42)\n",
    "train_set = raw_train_set.shuffle(5000, seed=42).batch(32).prefetch(1)\n",
    "valid_set = raw_valid_set.batch(32).prefetch(1)\n",
    "test_set = raw_test_set.batch(32).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "351f12be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This was an absolutely terrible movie. Don't be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be their worst role in history. Even their great acting  ...\n",
      "Label: 0\n",
      "I have been known to fall asleep during films, but this is usually due to a combination of things including, really tired, being warm and comfortable on the sette and having just eaten a lot. However  ...\n",
      "Label: 0\n",
      "Mann photographs the Alberta Rocky Mountains in a superb fashion, and Jimmy Stewart and Walter Brennan give enjoyable performances as they always seem to do. <br /><br />But come on Hollywood - a Moun ...\n",
      "Label: 0\n",
      "This is the kind of film for a snowy Sunday afternoon when the rest of the world can go ahead with its own business as you descend into a big arm-chair and mellow for a couple of hours. Wonderful perf ...\n",
      "Label: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-13 16:21:59.391853: I tensorflow/core/kernels/data/tf_record_dataset_op.cc:387] The default buffer size is 262144, which is overridden by the user specified `buffer_size` of 8388608\n",
      "2025-06-13 16:21:59.396933: W tensorflow/core/kernels/data/cache_dataset_ops.cc:916] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2025-06-13 16:21:59.397032: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "for review, label in raw_train_set.take(4):\n",
    "    print(review.numpy().decode(\"utf-8\")[:200], \"...\")\n",
    "    print(\"Label:\", label.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3d4303",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 1000\n",
    "text_vec_layer = tf.keras.layers.TextVectorization(max_tokens=vocab_size)\n",
    "text_vec_layer.adapt(train_set.map(lambda reviews, labels: reviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abbeb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 128\n",
    "tf.random.set_seed(42)\n",
    "model = tf.keras.Sequential([\n",
    "    text_vec_layer,\n",
    "    # input is with size token numbers x dimension for GRU\n",
    "    tf.keras.layers.Embedding(vocab_size, embed_size),\n",
    "    tf.keras.layers.GRU(128),\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"nadam\",\n",
    "              metrics=[\"accuracy\"])\n",
    "history = model.fit(train_set, validation_data=valid_set, epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa9e59f",
   "metadata": {},
   "source": [
    "### Masking\n",
    "\n",
    "basically skipping the time steps where the token are 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50b82ab",
   "metadata": {},
   "source": [
    "### Reusing Pretrained Embeddings and Language Models\n",
    "\n",
    "Due to the limitation of each word only have 1 embedding (though 1 word can mean different things), we can contextualize word embeddings learned from the internal states of a deep bidirectional language model. So instead of just using pretrained embeddings in the model, we reuse part of a pretrained language model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f655fbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "os.environ[\"TFHUB_CACHE_DIR\"] = \"my_tfhub_cache\"\n",
    "tf.random.set_seed(42)  # extra code – ensures reproducibility on CPU\n",
    "model = tf.keras.Sequential([\n",
    "    hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
    "                   trainable=True, dtype=tf.string, input_shape=[]),\n",
    "    tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"nadam\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_set, validation_data=valid_set, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026081ab",
   "metadata": {},
   "source": [
    "## An Encoder-Decoder Network for Neural Machine Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786ce05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\"\n",
    "path = tf.keras.utils.get_file(\"spa-eng.zip\", origin=url, cache_dir=\"datasets\",\n",
    "                               extract=True)\n",
    "text = (Path(path).with_name(\"spa-eng\") / \"spa.txt\").read_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2de0c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "text = text.replace(\"¡\", \"\").replace(\"¿\", \"\")\n",
    "pairs = [line.split(\"\\t\") for line in text.splitlines()]\n",
    "np.random.seed(42)  # extra code – ensures reproducibility on CPU\n",
    "np.random.shuffle(pairs)\n",
    "sentences_en, sentences_es = zip(*pairs)  # separates the pairs into 2 lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3def1eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    print(sentences_en[i], \"=>\", sentences_es[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05a7145",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 1000\n",
    "max_length = 50\n",
    "# for english sentences\n",
    "text_vec_layer_en = tf.keras.layers.TextVectorization(\n",
    "    vocab_size, output_sequence_length=max_length)\n",
    "text_vec_layer_en.adapt(sentences_en)\n",
    "\n",
    "# for spanish sentences\n",
    "text_vec_layer_es = tf.keras.layers.TextVectorization(\n",
    "    vocab_size, output_sequence_length=max_length)\n",
    "text_vec_layer_es.adapt([f\"startofseq {s} endofseq\" for s in sentences_es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22405ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokens from the first english sentence\n",
    "text_vec_layer_en.get_vocabulary()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a36dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokens from the first spanish sentence\n",
    "text_vec_layer_es.get_vocabulary()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0ae10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = tf.keras.layers.Input(shape=[], dtype=tf.string)\n",
    "decoder_inputs = tf.keras.layers.Input(shape=[], dtype=tf.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e82c00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tf.constant(sentences_en[:100_000])\n",
    "X_valid = tf.constant(sentences_en[100_000:])\n",
    "# for decoder\n",
    "X_train_dec = tf.constant([f\"startofseq {s}\" for s in sentences_es[:100_000]])\n",
    "X_valid_dec = tf.constant([f\"startofseq {s}\" for s in sentences_es[100_000:]])\n",
    "\n",
    "# target\n",
    "Y_train = text_vec_layer_es([f\"{s} endofseq\" for s in sentences_es[:100_000]])\n",
    "Y_valid = text_vec_layer_es([f\"{s} endofseq\" for s in sentences_es[100_000:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97683e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 128\n",
    "\n",
    "# for encoder\n",
    "encoder_input_ids = text_vec_layer_en(encoder_inputs)\n",
    "encoder_embedding_layer = tf.keras.layers.Embedding(vocab_size, embed_size, \n",
    "                                                    mask_zero=True)\n",
    "encoder_embeddings = encoder_embedding_layer(encoder_input_ids)\n",
    "\n",
    "# for decoder\n",
    "decoder_input_ids = text_vec_layer_es(decoder_inputs)\n",
    "decoder_embedding_layer = tf.keras.layers.Embedding(vocab_size, embed_size, \n",
    "                                                    mask_zero=True)\n",
    "decoder_embeddings = decoder_embedding_layer(decoder_input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd08fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# return_state = True to ensure that we get a reference\n",
    "# to the layer's final state\n",
    "encoder = tf.keras.layers.LSTM(512, return_state=True)\n",
    "# output, *short-term and long-term state\n",
    "encoder_outputs, *encoder_state = encoder(encoder_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3adff7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = tf.keras.layers.LSTM(512, return_sequences=True)\n",
    "# use the encoder_state as the initial_state for the decoder\n",
    "decoder_outputs = decoder(decoder_embeddings, initial_state=encoder_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d91e0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_layer = tf.keras.layers.Dense(vocab_size, activation=\"softmax\")\n",
    "Y_proba = output_layer(decoder_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f41123",
   "metadata": {},
   "source": [
    "When the target vocabulary gets incredibly large, ocnsider the *sampled softmax* technique where the loss is calculated using the logits of the correct word and random sample of incorrect words.\n",
    "\n",
    "`tf.nn.sample_softmax_loss()` function for training and use the normal softmax function at inference time.\n",
    "\n",
    "Another way to speed up training is to tie the weights of the output layer to the transpose of the decoder's embedding matrix which can significantly reduce the number of model parameters (essentially having an *orthogonal matrix* for the embedding matrix)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f5f4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Model(inputs =[encoder_inputs, decoder_inputs],\n",
    "                       outputs=[Y_proba])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit((X_train, X_train_dec), Y_train, epochs=10,\n",
    "          validation_data=((X_valid, X_valid_dec), Y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a2a22e",
   "metadata": {},
   "source": [
    "To use the model, use the following utility function!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66b8366",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(sentence_en):\n",
    "    translation = \"\"\n",
    "    for word_idx in range(max_length):\n",
    "        X = np.array([sentence_en])\n",
    "        X_dec = np.array([\"startofseq\" + translation])\n",
    "        y_proba = model.predict((X, X_dec))[0, word_idx]\n",
    "        predicted_word_id = np.argmax(y_proba)\n",
    "        predicted_word = text_vec_layer_es.get_vocabulary()[predicted_word_id]\n",
    "        if predicted_word == \"endofseq\":\n",
    "            break\n",
    "        translation += \" \" + predicted_word\n",
    "    return translation.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4888da22",
   "metadata": {},
   "outputs": [],
   "source": [
    "translate(\"I like soccer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f1d818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# can struggle with long sentences\n",
    "translate(\"I like soccer and also going to the beach\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd7df90",
   "metadata": {},
   "source": [
    "Methods of improving is either to increase the training set size and add more LSTM layers in both the encoder and decoder. Another method is to use bidirectional recurrent layers / Bidirectional RNNs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ee7a90",
   "metadata": {},
   "source": [
    "### Bidirectional RNNs\n",
    "\n",
    "Normally, a regular recorrent layer only looks at the past and present inputs before generating its output *causal* (cannot look to the future). However, for tasks like text classification, or in the encoder of a seq2seq model, it is often preferable to look ahead at the next words before encoding a given word.\n",
    "\n",
    "*bidirectional recurrent layer* are 2 recurrent layers on the same input, one reading the word from left to right, and the other reading from right to lect, then combine their outputs at each time step (by concatenating them)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8bc73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a close of the GRU layer and runs both and concatenate their outputs!\n",
    "encoder = tf.keras.layers.Bidirectional(\n",
    "    tf.leras.layers.LSTM(256, return_state=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108c3f78",
   "metadata": {},
   "source": [
    "Since this will result in have 4 encoder state outputs (short and long term for left to right; short and long term for right to left), we will concatenate the short and long terms together!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b1d41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_outputs, *encoder_state = encoder(encoder_embeddings)\n",
    "encoder_state = [tf.concat(encoder_state[::2], axis=-1), # short-term (0 & 2)\n",
    "                 tf.concat(encoder_state[1::2], axis=-1)] # long-term (1 & 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78712ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra code — completes the model and trains it\n",
    "decoder = tf.keras.layers.LSTM(512, return_sequences=True)\n",
    "decoder_outputs = decoder(decoder_embeddings, initial_state=encoder_state)\n",
    "output_layer = tf.keras.layers.Dense(vocab_size, activation=\"softmax\")\n",
    "Y_proba = output_layer(decoder_outputs)\n",
    "model = tf.keras.Model(inputs=[encoder_inputs, decoder_inputs],\n",
    "                       outputs=[Y_proba])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit((X_train, X_train_dec), Y_train, epochs=10,\n",
    "          validation_data=((X_valid, X_valid_dec), Y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b517b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "translate(\"I like soccer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83e5a28",
   "metadata": {},
   "source": [
    "### Beam Search\n",
    "\n",
    "Keeping track of a short list of the *k* most promising sentence, and at each decoder step it tries to extend them by one word, keeping only the *k* most likely sentence. The *k* is called *beam width*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2507921b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra code – a basic implementation of beam search\n",
    "\n",
    "def beam_search(sentence_en, beam_width, verbose=False):\n",
    "    X = np.array([sentence_en])  # encoder input\n",
    "    X_dec = np.array([\"startofseq\"])  # decoder input\n",
    "    y_proba = model.predict((X, X_dec))[0, 0]  # first token's probas\n",
    "    top_k = tf.math.top_k(y_proba, k=beam_width)\n",
    "    top_translations = [  # list of best (log_proba, translation)\n",
    "        (np.log(word_proba), text_vec_layer_es.get_vocabulary()[word_id])\n",
    "        for word_proba, word_id in zip(top_k.values, top_k.indices)\n",
    "    ]\n",
    "    \n",
    "    # extra code – displays the top first words in verbose mode\n",
    "    if verbose:\n",
    "        print(\"Top first words:\", top_translations)\n",
    "\n",
    "    for idx in range(1, max_length):\n",
    "        candidates = []\n",
    "        for log_proba, translation in top_translations:\n",
    "            if translation.endswith(\"endofseq\"):\n",
    "                candidates.append((log_proba, translation))\n",
    "                continue  # translation is finished, so don't try to extend it\n",
    "            X = np.array([sentence_en])  # encoder input\n",
    "            X_dec = np.array([\"startofseq \" + translation])  # decoder input\n",
    "            y_proba = model.predict((X, X_dec))[0, idx]  # last token's proba\n",
    "            for word_id, word_proba in enumerate(y_proba):\n",
    "                word = text_vec_layer_es.get_vocabulary()[word_id]\n",
    "                candidates.append((log_proba + np.log(word_proba),\n",
    "                                   f\"{translation} {word}\"))\n",
    "        top_translations = sorted(candidates, reverse=True)[:beam_width]\n",
    "\n",
    "        # extra code – displays the top translation so far in verbose mode\n",
    "        if verbose:\n",
    "            print(\"Top translations so far:\", top_translations)\n",
    "\n",
    "        if all([tr.endswith(\"endofseq\") for _, tr in top_translations]):\n",
    "            return top_translations[0][1].replace(\"endofseq\", \"\").strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa2b0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra code – shows how the model making an error\n",
    "sentence_en = \"I love cats and dogs\"\n",
    "translate(sentence_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59968758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra code – shows how beam search can help\n",
    "beam_search(sentence_en, beam_width=3, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050cb6b3",
   "metadata": {},
   "source": [
    "## Attention Mechanisms\n",
    "\n",
    "Allowing the decoder to focus on the appropriate words (as encoded by the encoder) at each time step. This means that the short-term memory limitations of RNNs have much less impact.\n",
    "\n",
    "In between the encoder and decoder model, we now send all of the encoder's outputs to the decoder as well and aggregate the encoder output where at each time step, the decoder's memory cell computes a WEIGHTED sum of all the encoder outputs (determining which word it will focus on at this step).\n",
    "\n",
    "The weights are generated by a small neural network called an *alignment model* (or an *attention layer*), which is trained jointly with the rest of the encoder-decoder model. Since the attention layer concatenates the encoder output with the decoder's previous hidden state, it is sometimes called *concatenative attention* (or *additive attention*).\n",
    "\n",
    "There is also the *multiplicative attention* where the dot product between the encoder's output and decoder's previous hidden state is computed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff85d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)  # extra code – ensures reproducibility on CPU\n",
    "encoder = tf.keras.layers.Bidirectional(\n",
    "    tf.keras.layers.LSTM(256, return_sequences=True, return_state=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d62f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra code – this part of the model is exactly the same as earlier\n",
    "encoder_outputs, *encoder_state = encoder(encoder_embeddings)\n",
    "encoder_state = [tf.concat(encoder_state[::2], axis=-1),  # short-term (0 & 2)\n",
    "                 tf.concat(encoder_state[1::2], axis=-1)]  # long-term (1 & 3)\n",
    "decoder = tf.keras.layers.LSTM(512, return_sequences=True)\n",
    "decoder_outputs = decoder(decoder_embeddings, initial_state=encoder_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3bcf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_layer = tf.keras.layers.Attention()\n",
    "attention_outputs = attention_layer([decoder_outputs, encoder_outputs])\n",
    "output_layer = tf.keras.layers.Dense(vocab_size, activation = \"softmax\")\n",
    "Y_proba = output_layer(attention_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539a8e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Model(inputs=[encoder_inputs, decoder_inputs],\n",
    "                       outputs=[Y_proba])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit((X_train, X_train_dec), Y_train, epochs=10,\n",
    "          validation_data=((X_valid, X_valid_dec), Y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab3402d",
   "metadata": {},
   "outputs": [],
   "source": [
    "translate(\"I like soccer and also going to the beach\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981c75a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "beam_search(\"I like soccer and also going to the beach\", beam_width=3,\n",
    "            verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f72091f",
   "metadata": {},
   "source": [
    "### Attention is All You Need: The Original Transformer Architecture\n",
    "\n",
    "Each embedding layer outputs a 3D tensor of a shape [batch size, sequence length, embedding size].\n",
    "\n",
    "The encoder is to transform the inputs until each word's representation perfectly captures the meaning of the word. While the decoder is to gradually transform each word representation in the translated sentence into a word representation of the next word in the translatio."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04856786",
   "metadata": {},
   "source": [
    "#### Positional encodings\n",
    "\n",
    "Without positional encodings, we can shuffle the input sequence and output sequences in the same way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8933da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 50\n",
    "embed_size = 128\n",
    "pos_embed_layer = tf.keras.layers.Embedding(max_length, embed_size)\n",
    "batch_max_len_enc = tf.shape(encoder_embeddings)[1]\n",
    "encoder_in = encoder_embeddings + pos_embed_layer (tf.range(batch_max_len_enc))\n",
    "batch_max_len_dec = tf.shape(decoder_embeddings)[1]\n",
    "decoder_in = decoder_embeddings + pos_embed_layer(tf.range(batch_max_len_dec))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c57492",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "    def __init__(self, max_length, embed_size, dtype=tf.float32, **kwargs):\n",
    "        super().__init__(dtype=dtype, **kwargs)\n",
    "        assert embed_size % 2 == 0, \"embed_size must be even\"\n",
    "        p, i = np.meshgrid(np.arange(max_length),\n",
    "                           2 * np.arange(embed_size // 2))\n",
    "        pos_emb = np.empty((1, max_length, embed_size))\n",
    "        pos_emb[0, :, ::2] = np.sin(p / 10_000 ** (i / embed_size)).T\n",
    "        pos_emb[0, :, 1::2] = np.cos(p / 10_000 ** (i / embed_size)).T\n",
    "        self.pos_encodings = tf.constant(pos_emb.astype(self.dtype))\n",
    "        self.supports_masking = True\n",
    "\n",
    "    def call(self, inputs):\n",
    "        batch_max_length = tf.shape(inputs)[1]\n",
    "        return inputs + self.pos_encodings[:, :batch_max_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8751cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_embed_layer = PositionalEncoding(max_length, embed_size)\n",
    "encoder_in = pos_embed_layer(encoder_embeddings)\n",
    "decoder_in = pos_embed_layer(decoder_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4663555f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra code – this cells generates and saves Figure 16–9\n",
    "figure_max_length = 201\n",
    "figure_embed_size = 512\n",
    "pos_emb = PositionalEncoding(figure_max_length, figure_embed_size)\n",
    "zeros = np.zeros((1, figure_max_length, figure_embed_size), np.float32)\n",
    "P = pos_emb(zeros)[0].numpy()\n",
    "i1, i2, crop_i = 100, 101, 150\n",
    "p1, p2, p3 = 22, 60, 35\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=2, ncols=1, sharex=True, figsize=(9, 5))\n",
    "ax1.plot([p1, p1], [-1, 1], \"k--\", label=\"$p = {}$\".format(p1))\n",
    "ax1.plot([p2, p2], [-1, 1], \"k--\", label=\"$p = {}$\".format(p2), alpha=0.5)\n",
    "ax1.plot(p3, P[p3, i1], \"bx\", label=\"$p = {}$\".format(p3))\n",
    "ax1.plot(P[:,i1], \"b-\", label=\"$i = {}$\".format(i1))\n",
    "ax1.plot(P[:,i2], \"r-\", label=\"$i = {}$\".format(i2))\n",
    "ax1.plot([p1, p2], [P[p1, i1], P[p2, i1]], \"bo\")\n",
    "ax1.plot([p1, p2], [P[p1, i2], P[p2, i2]], \"ro\")\n",
    "ax1.legend(loc=\"center right\", fontsize=14, framealpha=0.95)\n",
    "ax1.set_ylabel(\"$P_{(p,i)}$\", rotation=0, fontsize=16)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.hlines(0, 0, figure_max_length - 1, color=\"k\", linewidth=1, alpha=0.3)\n",
    "ax1.axis([0, figure_max_length - 1, -1, 1])\n",
    "ax2.imshow(P.T[:crop_i], cmap=\"gray\", interpolation=\"bilinear\", aspect=\"auto\")\n",
    "ax2.hlines(i1, 0, figure_max_length - 1, color=\"b\", linewidth=3)\n",
    "cheat = 2  # need to raise the red line a bit, or else it hides the blue one\n",
    "ax2.hlines(i2+cheat, 0, figure_max_length - 1, color=\"r\", linewidth=3)\n",
    "ax2.plot([p1, p1], [0, crop_i], \"k--\")\n",
    "ax2.plot([p2, p2], [0, crop_i], \"k--\", alpha=0.5)\n",
    "ax2.plot([p1, p2], [i2+cheat, i2+cheat], \"ro\")\n",
    "ax2.plot([p1, p2], [i1, i1], \"bo\")\n",
    "ax2.axis([0, figure_max_length - 1, 0, crop_i])\n",
    "ax2.set_xlabel(\"$p$\", fontsize=16)\n",
    "ax2.set_ylabel(\"$i$\", rotation=0, fontsize=16)\n",
    "save_fig(\"positional_embedding_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91b42d5",
   "metadata": {},
   "source": [
    "#### Multi-head attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cc0c6e",
   "metadata": {},
   "source": [
    "*Scaled dot-product attention*\n",
    "\n",
    "Attention (**Q**, **K**, **V**) = softmax($QK^T \\over \\sqrt{d_{keys}}$) V\n",
    "\n",
    "Output has shape [n queries, d values] or one row per query, where aech row represents the query result (weighted sum of the values).\n",
    "\n",
    "- Q = Matrix with 1 row / *query*. Shape of [n queries, d keys], where n queries is the number of queries and d keys is the number of dimensions of each query and each key.\n",
    "- K = Matrix containing 1 row / *key*. Shape of [n keys, d keys]\n",
    "- V = Matrix containing 1 row / *value*. Shape of [n keys, d values]\n",
    "\n",
    "\n",
    "Multi-head attention layer applies *multiple* different linear transformation of the values, keys and queries as it allows the model to apply many different projections of the word representation into different subspcaes, each focusing on a subset of the wrod's characteristics (layer of verb, present tense, object, etc)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7071235b",
   "metadata": {},
   "source": [
    "**Encoder Part**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1751b7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 2  # instead of 6\n",
    "num_heads = 8\n",
    "dropout_rate = 0.1\n",
    "n_units = 128  # for the first Dense layer in each Feed Forward block\n",
    "encoder_pad_mask = tf.math.not_equal(encoder_input_ids, 0)[:, tf.newaxis]\n",
    "Z = encoder_in\n",
    "for _ in range(N):\n",
    "    skip = Z\n",
    "    attn_layer = tf.keras.layers.MultiHeadAttention(\n",
    "        num_heads=num_heads, key_dim=embed_size, dropout=dropout_rate)\n",
    "    Z = attn_layer(Z, value=Z, attention_mask=encoder_pad_mask)\n",
    "    Z = tf.keras.layers.LayerNormalization()(tf.keras.layers.Add()([Z, skip]))\n",
    "    skip = Z\n",
    "    Z = tf.keras.layers.Dense(n_units, activation=\"relu\")(Z)\n",
    "    Z = tf.keras.layers.Dense(embed_size)(Z)\n",
    "    Z = tf.keras.layers.Dropout(dropout_rate)(Z)\n",
    "    Z = tf.keras.layers.LayerNormalization()(tf.keras.layers.Add()([Z, skip]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10d9bc4",
   "metadata": {},
   "source": [
    "**Decoder part**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3eb18af",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_pad_mask = tf.math.not_equal(decoder_input_ids, 0)[:, tf.newaxis]\n",
    "# should ignore all tokens in the future, hence the lower triangular matrix\n",
    "causal_mask = tf.linalg.band_part(  # creates a lower triangular matrix\n",
    "    tf.ones((batch_max_len_dec, batch_max_len_dec), tf.bool), -1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8624e365",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_outputs = Z  # let's save the encoder's final outputs\n",
    "Z = decoder_in  # the decoder starts with its own inputs\n",
    "for _ in range(N):\n",
    "    skip = Z\n",
    "    attn_layer = tf.keras.layers.MultiHeadAttention(\n",
    "        num_heads=num_heads, key_dim=embed_size, dropout=dropout_rate)\n",
    "    Z = attn_layer(Z, value=Z, attention_mask=causal_mask & decoder_pad_mask)\n",
    "    Z = tf.keras.layers.LayerNormalization()(tf.keras.layers.Add()([Z, skip]))\n",
    "    skip = Z\n",
    "    attn_layer = tf.keras.layers.MultiHeadAttention(\n",
    "        num_heads=num_heads, key_dim=embed_size, dropout=dropout_rate)\n",
    "    # note that the input here is the encoder_outputs\n",
    "    Z = attn_layer(Z, value=encoder_outputs, attention_mask=encoder_pad_mask)\n",
    "    Z = tf.keras.layers.LayerNormalization()(tf.keras.layers.Add()([Z, skip]))\n",
    "    skip = Z\n",
    "    Z = tf.keras.layers.Dense(n_units, activation=\"relu\")(Z)\n",
    "    Z = tf.keras.layers.Dense(embed_size)(Z)\n",
    "    Z = tf.keras.layers.LayerNormalization()(tf.keras.layers.Add()([Z, skip]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81850697",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_proba = tf.keras.layers.Dense(vocab_size, activation=\"softmax\")(Z)\n",
    "model = tf.keras.Model(inputs=[encoder_inputs, decoder_inputs],\n",
    "                       outputs=[Y_proba])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit((X_train, X_train_dec), Y_train, epochs=10,\n",
    "          validation_data=((X_valid, X_valid_dec), Y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c5b018",
   "metadata": {},
   "outputs": [],
   "source": [
    "translate(\"I like soccer and also going to the beach\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f4112b",
   "metadata": {},
   "source": [
    "## An Avalanche of Transofmer Models\n",
    "\n",
    "- GPT Paper by Alec Radford and other OpenAI researchers, showing the effectiveness of unsupervised pretraiing using the transformer-like architecture. It was capable of many tasks such as text classification, *entailment*, similarity, question answering.\n",
    "\n",
    "- Google's BERT paper, demonstrating effectiveness of self-supervised pretraining on a large corpus.\n",
    "\n",
    "    - Masked Language Model (MLM), where each word in a sentence has a 15% probability of being masked and the model is trained to predict the masked words.\n",
    "    - Next sentenced prediction (NSP), model is trained to predict whether 2 sentences are consecutive or not.\n",
    "\n",
    "- GPT-2, by OpenAI . Improvement on GPT model for *zero-shot laerning* where it could achieve good performance on many tasks without fine-tuning.\n",
    "\n",
    "- DistilBERT, by Hugging Face, is a small and fast transformer model based on BERT. Trained using *distillation* / transferring knowledge from a teacher model to a student one, which usually is much smaller than the teacher model. Typically done by using the teacher's predicted probabilities for each training instance as targets for the student.\n",
    "\n",
    "- T5, framing all NLP tasks as text-to-text, using an encoder-decoder transformer. Where to translate \"translate English to Spanish: I like soccer\", \"summarize: {paragraph}\", \"classify: {paragraph}\", etc.\n",
    "\n",
    "- Pathways Languange Model (PaLM), using only decoders with masked multi-head attention layers, the model achieved incredible performance on all sorts of NLP tasks, including natural language understanding (NLU) through the use of *Chain of thought prompting*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1dfbf1",
   "metadata": {},
   "source": [
    "## Vision Transformers\n",
    "\n",
    "**Visual Attention**, where a convolutional neural network first processes the image and outputs some feature maps, then a decoder RNN equipped with an attention mechanism generates the caption, one word at a time.\n",
    "\n",
    "At each decoder time step, the decoder uses the attention model to focus on just the right part of the image.\n",
    "\n",
    "Also, attention mechanisms seem to enable scientist to make it easier to understand what led the model to produce its outputs!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f12dda",
   "metadata": {},
   "source": [
    "Facebook researches propposed a hybrid CNN-transformer architecture for object detection, where the CNN first processes the input imaves and outputs a set of feature maps, then these feature maps are converted to sequences and fed to a transformer, which outputs bounding box predictions.\n",
    "\n",
    "Google introduced a fully transformer-based vision model *vision transformer* (ViT) where the images is chopped to 16 x 16 squares, and treat the sequence of squares as if it were a sequence of word representations.\n",
    "1. 16x16x3 (RGB) flattened sequence\n",
    "2. Use lineary layer to transform them\n",
    "3. Add positional embeddings\n",
    "4. Pass the result into a transformer.\n",
    "\n",
    "Then Facebook introduced the *data-efficient image transformers* (DeiTs), where they used a distillation technique to transfer knowledge from state-of-the-art CNN models to their model.\n",
    "\n",
    "Deepmind then introduced the *Perceiver* architecture which is a *multimodal* transformer (input can be text, images, audio, etc). The architecture solves the problem of self-attention growing to a large size (since for a sequence of M tokens, the model must compute a M x M matrix for the attention layer), by improving a fairly short *latent (hidden, internal) representation* of the inputs composed of N tokens (typically just a few hundred). (look up what *cross-attention layers* mean). The model uses cross-attention layers only and feeds them the latent representation as queries so it only requires the model to compute M x N matrix.\n",
    "\n",
    "DINO, an impressive vision transformer trained entirely without labels, using self-supervision, and capable of high-accuracy semantic segmentation. Uses a technique called *self-distillation* where again a teacher and student model is used, where both initially has the same model but gradient descent only affects the student while the teacher's weights are the student's exponential moving average of the student's weights. (so they're basically almost the same model!)\n",
    "\n",
    "Others include CLIP, DALL-E, GATO, Flamingo, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c47bc00",
   "metadata": {},
   "source": [
    "## Hugging Face's Transfomers Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "604fcd66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevinkyhalim/ML_repo/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "All PyTorch model weights were used when initializing TFDistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of TFDistilBertForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n",
      "Device set to use 0\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\")  # many other tasks are available\n",
    "result = classifier(\"The actors were very convincing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5dfd5385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9998071789741516}]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f50d5c74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9896161556243896},\n",
       " {'label': 'NEGATIVE', 'score': 0.9811071157455444}]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier([\"I am from India.\", \"I am from Iraq.\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "158bc3d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9860380291938782}]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"I am from Indonesia.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fe55b882",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "All PyTorch model weights were used when initializing TFDistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of TFDistilBertForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n",
      "Device set to use 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'contradiction', 'score': 0.9790191650390625}]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"huggingface/distilbert-base-uncased-finetuned-mnli\"\n",
    "classifier_mnli = pipeline(\"text-classification\", model=model_name)\n",
    "classifier_mnli(\"She loves me. [SEP] She loves me not.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8995d155",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFDistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of TFDistilBertForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e9d08419",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': <tf.Tensor: shape=(2, 15), dtype=int32, numpy=\n",
       "array([[ 101, 1045, 2066, 4715, 1012,  102, 2057, 2035, 2293, 4715,  999,\n",
       "         102,    0,    0,    0],\n",
       "       [ 101, 3533, 2973, 2005, 1037, 2200, 2146, 2051, 1012,  102, 3533,\n",
       "        2003, 2214, 1012,  102]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(2, 15), dtype=int32, numpy=\n",
       "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
       "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=int32)>}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_ids = tokenizer([\"I like soccer. [SEP] We all love soccer!\",\n",
    "                       \"Joe lived for a very long time. [SEP] Joe is old.\"],\n",
    "                      padding=True, return_tensors=\"tf\")\n",
    "token_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929e02b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': <tf.Tensor: shape=(2, 15), dtype=int32, numpy=\n",
       "array([[ 101, 1045, 2066, 4715, 1012,  102, 2057, 2035, 2293, 4715,  999,\n",
       "         102,    0,    0,    0],\n",
       "       [ 101, 3533, 2973, 2005, 1037, 2200, 2146, 2051, 1012,  102, 3533,\n",
       "        2003, 2214, 1012,  102]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(2, 15), dtype=int32, numpy=\n",
       "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
       "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=int32)>}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# same as above, just written differently\n",
    "token_ids = tokenizer([(\"I like soccer.\", \"We all love soccer!\"),\n",
    "                       (\"Joe lived for a very long time.\", \"Joe is old.\")],\n",
    "                      padding=True, return_tensors=\"tf\")\n",
    "token_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "995132d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TFSequenceClassifierOutput(loss=None, logits=<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[-2.1123815 ,  1.1786786 ,  1.4101012 ],\n",
       "       [-0.01478325,  1.0962472 , -0.99199563]], dtype=float32)>, hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = model(token_ids)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0d9bf496",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[0.01619702, 0.43523565, 0.5485674 ],\n",
       "       [0.22655982, 0.68817246, 0.08526779]], dtype=float32)>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_probas = tf.keras.activations.softmax(outputs.logits)\n",
    "Y_probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fd7cad41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int64, numpy=array([2, 1])>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred = tf.argmax(Y_probas, axis=1)\n",
    "Y_pred  # 0 = contradiction, 1 = entailment, 2 = neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "16688d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1/1 [==============================] - 11s 11s/step - loss: 1.0864 - accuracy: 0.5000\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 1.0324 - accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "sentences = [(\"Sky is blue\", \"Sky is red\"), (\"I love her\", \"She loves me\")]\n",
    "X_train = tokenizer(sentences, padding=True, return_tensors=\"tf\").data\n",
    "y_train = tf.constant([0, 2])  # contradiction, neutral\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "model.compile(loss=loss, optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "history = model.fit(X_train, y_train, epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df58e7f8",
   "metadata": {},
   "source": [
    "Check out the O’Reilly book Natural Language Processing with Transformers: Building Language Applications with Hugging Face by Lewis Tunstall, Leandro von Werra, and Thomas Wolf—all from the Hugging Face team."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5132bd10",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a051570",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
